{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jxv6goXm7oGF"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llMNufAK7nfK"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Byow2J6LaPl"
   },
   "source": [
    "# Better performance with tf.function and AutoGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CydFK2CL7ZHA"
   },
   "source": [
    "TF 2.0 brings together the ease of eager execution and the power of TF 1.0. At the center of this merger is `tf.function`, which allows you to transform a subset of Python syntax into portable, high-performance TensorFlow graphs.\n",
    "\n",
    "A cool new feature of `tf.function` is AutoGraph, which lets you write graph code using natural Python syntax. For a list of the Python features that you can use with AutoGraph, see [AutoGraph Capabilities and Limitations](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md). For more details about `tf.function`, see the RFC [TF 2.0: Functions, not Sessions](https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md). For more details about AutoGraph, see `tf.autograph`.\n",
    "\n",
    "This tutorial will walk you through the basic features of `tf.function` and AutoGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4EKOpw9mObL"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Import TensorFlow 2.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9oECvVSI1Kj"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mT7meGqrZTz9"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77AsVr1GGtBP"
   },
   "source": [
    "## The `tf.function` decorator\n",
    "\n",
    "When you annotate a function with `tf.function`, you can still call it like any other function. But it will be compiled into a graph, which means you get the benefits of faster execution, running on GPU or TPU, or exporting to SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhIg7-z6HNWj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.25601318, 0.38919708, 0.34901285],\n",
       "       [0.14291635, 0.3470501 , 0.2846484 ],\n",
       "       [0.16643555, 0.366066  , 0.5762576 ]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_nn_layer(x, y):\n",
    "  return tf.nn.relu(tf.matmul(x, y))\n",
    "\n",
    "\n",
    "x = tf.random.uniform((3, 3))\n",
    "y = tf.random.uniform((3, 3))\n",
    "\n",
    "simple_nn_layer(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-LAE4pMNR9g"
   },
   "source": [
    "If we examine the result of the annotation, we can see that it's a special callable that handles all interactions with the TensorFlow runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4t2iuS7Nqc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x20083f3e1c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqeefLGNXjZQ"
   },
   "source": [
    "If your code uses multiple functions, you don't need to annotate them all - any functions called from an annotated function will also run in graph mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VGF7tlVXiZY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 5, 7])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_layer(x):\n",
    "  return 2 * x + 1\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def deep_net(x):\n",
    "  return tf.nn.relu(linear_layer(x))\n",
    "\n",
    "\n",
    "deep_net(tf.constant((1, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQvg6ZSKWyqE"
   },
   "source": [
    "Functions can be faster than eager code, for graphs with many small ops. But for graphs with a few expensive ops (like convolutions), you may not see much speedup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0EL6lVwEWuFo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.7773740999982692\n",
      "Function conv: 0.6933108999946853\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "  return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "# warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000020083ECC6C8>\n",
      "<tensorflow.python.eager.def_function.Function object at 0x00000200E9AA9E48>\n"
     ]
    }
   ],
   "source": [
    "print(conv_layer)\n",
    "print(conv_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4zj-jpH0jKH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager lstm: 0.022824300001957454\n",
      "function lstm: 0.01508789999934379\n"
     ]
    }
   ],
   "source": [
    "lstm_cell = tf.keras.layers.LSTMCell(10)\n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "  return lstm_cell(input, state)\n",
    "\n",
    "input = tf.zeros([10, 10])\n",
    "state = [tf.zeros([10, 10])] * 2\n",
    "# warm up\n",
    "lstm_cell(input, state); lstm_fn(input, state)\n",
    "print(\"eager lstm:\", timeit.timeit(lambda: lstm_cell(input, state), number=10))\n",
    "print(\"function lstm:\", timeit.timeit(lambda: lstm_fn(input, state), number=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohbSnA79mcJV"
   },
   "source": [
    "## Use Python control flow\n",
    "\n",
    "When using data-dependent control flow inside `tf.function`, you can use Python control flow statements and AutoGraph will convert them into appropriate TensorFlow ops. For example, `if` statements will be converted into `tf.cond()` if they depend on a `Tensor`.\n",
    "\n",
    "In the example below, `x` is a `Tensor` but the `if` statement works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aA3gOodCBkOw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "square_if_positive(2) = 4\n",
      "square_if_positive(-2) = 0\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "  if x > 0:\n",
    "    x = x * x\n",
    "  else:\n",
    "    x = 0\n",
    "  return x\n",
    "\n",
    "print(square_if_positive(tf.constant(2)))\n",
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMiCUkdyoq98"
   },
   "source": [
    "Note: The previous example uses simple conditionals with scalar values. <a href=\"#batching\">Batching</a> is typically used in real-world code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-jWmsCmByyw"
   },
   "source": [
    "AutoGraph supports common Python statements like `while`, `for`, `if`, `break`, `continue` and `return`, with support for nesting. That means you can use `Tensor` expressions in the condition of `while` and `if` statements, or iterate over a `Tensor` in a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "toxKBOXbB1ro"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def sum_even(items):\n",
    "  s = 0\n",
    "  for c in items:\n",
    "    if c % 2 > 0:\n",
    "      continue\n",
    "    s += c\n",
    "  return s\n",
    "\n",
    "\n",
    "sum_even(tf.constant([10, 12, 15, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtDaLrbySw4j"
   },
   "source": [
    "AutoGraph also provides a low-level API for advanced users. For example we can use it to have a look at the generated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aRsde3x_SjTQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__sum_even(items):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('sum_even', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "    s = 0\n",
      "\n",
      "    def get_state_2():\n",
      "      return ()\n",
      "\n",
      "    def set_state_2(_):\n",
      "      pass\n",
      "\n",
      "    def loop_body(iterates, s):\n",
      "      c = iterates\n",
      "      continue_ = False\n",
      "\n",
      "      def get_state():\n",
      "        return ()\n",
      "\n",
      "      def set_state(_):\n",
      "        pass\n",
      "\n",
      "      def if_true():\n",
      "        continue_ = True\n",
      "        return continue_\n",
      "\n",
      "      def if_false():\n",
      "        return continue_\n",
      "      cond = c % 2 > 0\n",
      "      continue_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('continue_',), ())\n",
      "\n",
      "      def get_state_1():\n",
      "        return ()\n",
      "\n",
      "      def set_state_1(_):\n",
      "        pass\n",
      "\n",
      "      def if_true_1():\n",
      "        s_1, = s,\n",
      "        s_1 += c\n",
      "        return s_1\n",
      "\n",
      "      def if_false_1():\n",
      "        return s\n",
      "      cond_1 = ag__.not_(continue_)\n",
      "      s = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1, ('s',), ())\n",
      "      return s,\n",
      "    s, = ag__.for_stmt(items, None, loop_body, get_state_2, set_state_2, (s,), ('s',), ())\n",
      "    do_return = True\n",
      "    retval_ = fscope.mark_return_value(s)\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(sum_even.python_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvJXCfk8VkLf"
   },
   "source": [
    "Here's an example of more complicated control flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-Z87IJqVlKl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fizz\n",
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "  for i in tf.range(n):\n",
    "    if i % 3 == 0:\n",
    "      tf.print('Fizz')\n",
    "    elif i % 5 == 0:\n",
    "      tf.print('Buzz')\n",
    "    else:\n",
    "      tf.print(i)\n",
    "\n",
    "fizzbuzz(tf.constant(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_Y4uC1R1B55"
   },
   "source": [
    "## Keras and AutoGraph\n",
    "\n",
    "AutoGraph is available by default in non-dynamic Keras models. For more information, see `tf.keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cR6mpLKP1HLe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([-1, -2])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(tf.keras.models.Model):\n",
    "\n",
    "  @tf.function\n",
    "  def call(self, input_data):\n",
    "    if tf.reduce_mean(input_data) > 0:\n",
    "      return input_data\n",
    "    else:\n",
    "      return input_data // 2\n",
    "\n",
    "\n",
    "model = CustomModel()\n",
    "\n",
    "model(tf.constant([-2, -4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTEvpBK9f8kj"
   },
   "source": [
    "## Side effects\n",
    "\n",
    "Just like in eager mode, you can use operations with side effects, like `tf.assign` or `tf.print` normally inside `tf.function`, and it will insert the necessary control dependencies to ensure they execute in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Wd6i8S9gcuC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(5)\n",
    "\n",
    "@tf.function\n",
    "def find_next_odd():\n",
    "  v.assign(v + 1)\n",
    "  if v % 2 == 0:\n",
    "    v.assign(v + 1)\n",
    "\n",
    "\n",
    "find_next_odd()\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LfnJjm0Bm0B"
   },
   "source": [
    "<a id=\"debugging\"></a>\n",
    "\n",
    "## Debugging\n",
    "\n",
    "`tf.function` and AutoGraph work by generating code and tracing it into TensorFlow graphs. This mechanism does not yet support step-by-step debuggers like `pdb`. However, you can call `tf.config.run_functions_eagerly(True)` to temporarily enable eager execution inside the `tf.function' and use your favorite debugger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yci8ve6hmgpF"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  if x > 0:\n",
    "    # Try setting a breakpoint here!\n",
    "    # Example:\n",
    "    #   import pdb\n",
    "    #   pdb.set_trace()\n",
    "    x = x + 1\n",
    "  return x\n",
    "\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "# You can now set breakpoints and run the code in a debugger.\n",
    "f(tf.constant(1))\n",
    "\n",
    "tf.config.experimental_run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfpIQUv28Ht4"
   },
   "source": [
    "## Advanced example: An in-graph training loop\n",
    "\n",
    "The previous section showed that AutoGraph can be used inside Keras layers and models. Keras models can also be used in AutoGraph code.\n",
    "\n",
    "This example shows how to train a simple Keras model on MNIST with the entire training process—loading batches, calculating gradients, updating parameters, calculating validation accuracy, and repeating until convergence—is performed in-graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Em5dzSUOtLRP"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqoxumv0ssQW"
   },
   "outputs": [],
   "source": [
    "def prepare_mnist_features_and_labels(x, y):\n",
    "  x = tf.cast(x, tf.float32) / 255.0\n",
    "  y = tf.cast(y, tf.int64)\n",
    "  return x, y\n",
    "\n",
    "def mnist_dataset():\n",
    "  (x, y), _ = tf.keras.datasets.mnist.load_data()\n",
    "  ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "  ds = ds.map(prepare_mnist_features_and_labels)\n",
    "  ds = ds.take(20000).shuffle(20000).batch(100)\n",
    "  return ds\n",
    "\n",
    "train_dataset = mnist_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znmy4l8ntMvW"
   },
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ltxyJVWTqNAO"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential((\n",
    "    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)))\n",
    "model.build()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeYV6mKnJGMr"
   },
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xtg_MMhJETd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 : loss 1.89959216 ; accuracy 0.356\n",
      "Step 20 : loss 1.25947154 ; accuracy 0.4975\n",
      "Step 30 : loss 0.874856472 ; accuracy 0.587\n",
      "Step 40 : loss 0.661576748 ; accuracy 0.64475\n",
      "Step 50 : loss 0.45435676 ; accuracy 0.689\n",
      "Step 60 : loss 0.454364777 ; accuracy 0.718666673\n",
      "Step 70 : loss 0.469210893 ; accuracy 0.741571426\n",
      "Step 80 : loss 0.371560067 ; accuracy 0.75825\n",
      "Step 90 : loss 0.318025708 ; accuracy 0.774111092\n",
      "Step 100 : loss 0.334199548 ; accuracy 0.7854\n",
      "Step 110 : loss 0.372756034 ; accuracy 0.796454549\n",
      "Step 120 : loss 0.372888565 ; accuracy 0.80491668\n",
      "Step 130 : loss 0.406678617 ; accuracy 0.813461542\n",
      "Step 140 : loss 0.463483393 ; accuracy 0.820214272\n",
      "Step 150 : loss 0.37113446 ; accuracy 0.82586664\n",
      "Step 160 : loss 0.288563937 ; accuracy 0.8301875\n",
      "Step 170 : loss 0.222361416 ; accuracy 0.836529434\n",
      "Step 180 : loss 0.198517278 ; accuracy 0.840888917\n",
      "Step 190 : loss 0.350897193 ; accuracy 0.844947398\n",
      "Step 200 : loss 0.189548135 ; accuracy 0.84905\n",
      "Final step tf.Tensor(200, shape=(), dtype=int32) : loss tf.Tensor(0.18954813, shape=(), dtype=float32) ; accuracy tf.Tensor(0.84905, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = model(x)\n",
    "    loss = compute_loss(y, logits)\n",
    "\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  compute_accuracy(y, logits)\n",
    "  return loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train(model, optimizer):\n",
    "  train_ds = mnist_dataset()\n",
    "  step = 0\n",
    "  loss = 0.0\n",
    "  accuracy = 0.0\n",
    "  for x, y in train_ds:\n",
    "    step += 1\n",
    "    loss = train_one_step(model, optimizer, x, y)\n",
    "    if step % 10 == 0:\n",
    "      tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n",
    "  return step, loss, accuracy\n",
    "\n",
    "step, loss, accuracy = train(model, optimizer)\n",
    "print('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SnsumiP6eRYL"
   },
   "source": [
    "## Batching\n",
    "\n",
    "In real applications batching is essential for performance. The best code to convert to AutoGraph is code where the control flow is decided at the _batch_ level. If making decisions at the individual _example_ level, try to use batch APIs to maintain performance.\n",
    "\n",
    "For example, if you have the following code in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t31QoERiNccJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, -4, -3, -2, -1, 0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_if_positive(x):\n",
    "  return [i ** 2 if i > 0 else i for i in x]\n",
    "\n",
    "\n",
    "square_if_positive(range(-5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSeEJ76uNgwD"
   },
   "source": [
    "You may be tempted to write it in TensorFlow as such (and this would work!):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqR8WzSzNf87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def square_if_positive_naive(x):\n",
    "  result = tf.TensorArray(tf.int32, size=x.shape[0])\n",
    "  for i in tf.range(x.shape[0]):\n",
    "    if x[i] > 0:\n",
    "      result = result.write(i, x[i] ** 2)\n",
    "    else:\n",
    "      result = result.write(i, x[i])\n",
    "  return result.stack()\n",
    "\n",
    "\n",
    "square_if_positive_naive(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTcyWXVGN3gS"
   },
   "source": [
    "But in this case, it turns out you can write the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VO2f6x-lNfVj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_if_positive_vectorized(x):\n",
    "  return tf.where(x > 0, x ** 2, x)\n",
    "\n",
    "\n",
    "square_if_positive_vectorized(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.eager.def_function.function.<locals>.decorated(inner_function)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.function(\n",
    "    func=None,\n",
    "    input_signature=None,\n",
    "    autograph=True,\n",
    "    experimental_autograph_options=None,\n",
    "    experimental_relax_shapes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function constructs a callable that executes a TensorFlow graph (tf.Graph) created by tracing the TensorFlow operations in func. This allows the TensorFlow runtime to apply optimizations and exploit parallelism in the computation defined by func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "  return tf.reduce_mean(tf.multiply(x ** 2, 3) + y)\n",
    "\n",
    "g = tf.function(f)\n",
    "\n",
    "x = tf.constant([[2.0, 3.0]])\n",
    "y = tf.constant([[3.0, -2.0]])\n",
    "\n",
    "# `f` and `g` will return the same value, but `g` will be executed as a\n",
    "# TensorFlow graph.\n",
    "assert f(x, y).numpy() == g(x, y).numpy()\n",
    "\n",
    "# Tensors and tf.Variables used by the Python function are captured in the\n",
    "# graph.\n",
    "@tf.function\n",
    "def h():\n",
    "  return f(x, y)\n",
    "\n",
    "assert (h().numpy() == f(x, y).numpy()).all()\n",
    "\n",
    "# Data-dependent control flow is also captured in the graph. Supported\n",
    "# control flow statements include `if`, `for`, `while`, `break`, `continue`,\n",
    "# `return`.\n",
    "@tf.function\n",
    "def g(x):\n",
    "  if tf.reduce_sum(x) > 0:\n",
    "    return x * x\n",
    "  else:\n",
    "    return -x // 2\n",
    "\n",
    "# print and TensorFlow side effects are supported, but exercise caution when\n",
    "# using Python side effects like mutating objects, saving to files, etc.\n",
    "l = []\n",
    "\n",
    "@tf.function\n",
    "def g(x):\n",
    "  for i in x:\n",
    "    print(i)                              # Works\n",
    "    tf.compat.v1.assign(v, i)                       # Works\n",
    "    tf.compat.v1.py_func(lambda i: l.append(i))(i)  # Works\n",
    "    l.append(i)                           # Caution! Doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that unlike other TensorFlow operations, we don't convert python numerical inputs to tensors. Moreover, a new graph is generated for each distinct python numerical value, for example calling g(2) and g(3) will generate two new graphs (while only one is generated if you call g(tf.constant(2)) and g(tf.constant(3))). Therefore, python numerical inputs should be restricted to arguments that will have few distinct values, such as hyperparameters like the number of layers in a neural network. This allows TensorFlow to optimize each variant of the neural network.\n",
    "\n",
    "Referencing tf.Variables\n",
    "\n",
    "The Python function func may reference stateful objects (such as tf.Variable). These are captured as implicit inputs to the callable returned by function. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-5842a831edf9>:6: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "c = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  c.assign_add(1)\n",
    "  return x + tf.compat.v1.to_float(c)\n",
    "\n",
    "assert int(c) == 0\n",
    "assert f(1.0) == 2.0\n",
    "assert int(c) == 1\n",
    "assert f(1.0) == 3.0\n",
    "assert int(c) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function can be applied to methods of an object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(object):\n",
    "  def __init__(self):\n",
    "    self.W = tf.Variable(tf.compat.v1.glorot_uniform_initializer()((10, 10)))\n",
    "    self.b = tf.Variable(tf.zeros(10))\n",
    "\n",
    "  @tf.function\n",
    "  def compute(self, x):\n",
    "    return tf.matmul(x, self.W) + self.b\n",
    "\n",
    "d1 = Dense()\n",
    "d2 = Dense()\n",
    "x = tf.random.uniform((10, 10))\n",
    "# d1 and d2 are using distinct variables\n",
    "assert not (d1.compute(x).numpy() == d2.compute(x).numpy()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage with tf.keras\n",
    "\n",
    "The call methods of a tf.keras.Model subclass can be decorated with function in order to apply graph execution optimizations on it. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
       "array([[ 0.5005193 , -0.24730033, -1.0781333 , -0.43008655,  0.1037207 ],\n",
       "       [ 0.40461332, -0.30323812, -1.645912  , -0.6056957 ,  0.7527479 ],\n",
       "       [ 0.1423735 , -0.17650397, -1.3146888 , -0.3181464 , -0.25951898],\n",
       "       [ 0.12431064, -0.22373265, -1.0686699 , -0.28060383,  0.15386477],\n",
       "       [ 0.8766522 , -0.37231362, -1.0988556 , -0.62091374,  0.63209933],\n",
       "       [ 0.93118316, -0.37966034, -0.8750252 , -0.6006296 ,  0.7802803 ],\n",
       "       [-0.18786383,  0.09613264, -0.88458526, -0.19655176,  0.03370802],\n",
       "       [ 0.78455985, -0.37444085, -0.9614432 , -0.53267145,  0.54869545],\n",
       "       [ 0.4642647 , -0.2502508 , -1.1140661 , -0.4421596 ,  0.25081718],\n",
       "       [ 0.4145861 , -0.54091966, -1.2519972 , -0.33458346,  0.10882222]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, keep_probability=0.2):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(4)\n",
    "    self.dense2 = tf.keras.layers.Dense(5)\n",
    "    self.keep_probability = keep_probability\n",
    "\n",
    "  @tf.function\n",
    "  def call(self, inputs, training=True):\n",
    "    y = self.dense2(self.dense1(inputs))\n",
    "    if training:\n",
    "      return tf.nn.dropout(y, self.keep_probability)\n",
    "    else:\n",
    "      return y\n",
    "\n",
    "model = MyModel()\n",
    "model(x, training=True)  # executes a graph, with dropout\n",
    "model(x, training=False) # executes a graph, without dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Signatures\n",
    "\n",
    "function instantiates a separate graph for every unique set of input shapes and datatypes. For example, the following code snippet will result in three distinct graphs being traced, as each input has a different shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[4.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x): return tf.add(x, 1.)\n",
    "\n",
    "scalar = tf.constant(1.0)\n",
    "vector = tf.constant([1.0, 1.0])\n",
    "matrix = tf.constant([[3.0]])\n",
    "\n",
    "f(scalar)\n",
    "f(vector)\n",
    "f(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An \"input signature\" can be optionally provided to function to control the graphs traced. The input signature specifies the shape and type of each Tensor argument to the function using a tf.TensorSpec object. For example, the following code snippet ensures that a single graph is created where the input Tensor is required to be a floating point tensor with no restrictions on shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
    "def f(x): return tf.add(x, 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an input_signature is specified, the callable will convert the inputs to the specified TensorSpecs.\n",
    "\n",
    "Tracing and staging\n",
    "\n",
    "When autograph is True, all Python control flow that depends on Tensor values is staged into a TensorFlow graph. When autograph is False, the function is traced and control flow is not allowed to depend on data.\n",
    "\n",
    "Note that function only stages TensorFlow operations, all Python code that func executes and does not depend on data will shape the construction of the graph. For example, consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_noise():\n",
    "  return tf.eye(5) + np.random.randn(5, 5)\n",
    "\n",
    "traced = tf.function(add_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add_noise() will return a different output every time it is invoked. However, traced() will return the same value every time it is called, since a particular random value generated by the np.random.randn call will be inserted in the traced/staged TensorFlow graph as a constant. In this particular example, replacing np.random.randn(5, 5) with tf.random.normal((5, 5)) will result in the same behavior for add_noise() and traced().\n",
    "\n",
    "Python Side-Effects\n",
    "\n",
    "A corollary of the previous discussion on tracing is the following: If a Python function func has Python side-effects, then executing func multiple times may not be semantically equivalent to executing F = tf.function(func) multiple times; this difference is due to the fact that function only captures the subgraph of TensorFlow operations that is constructed when func is invoked to trace a graph.\n",
    "\n",
    "The same is true if code with Python side effects is used inside control flow, such as a loop. If your code uses side effects that are not intended to control graph construction, wrap them inside tf.compat.v1.py_func.\n",
    "\n",
    "Retracing\n",
    "\n",
    "A single tf.function object might need to map to multiple computation graphs under the hood. This should be visible only as performance (tracing graphs has a nonzero computational and memory cost) but should not affect the correctness of the program. A traced function should return the same result as it would when run eagerly, assuming no unintended Python side-effects.\n",
    "\n",
    "Calling a tf.function with tensor arguments of different dtypes should lead to at least one computational graph per distinct set of dtypes. Alternatively, always calling a tf.function with tensor arguments of the same shapes and dtypes and the same non-tensor arguments should not lead to additional retracings of your function.\n",
    "\n",
    "Other than that, TensorFlow reserves the right to retrace functions as many times as needed, to ensure that traced functions behave as they would when run eagerly and to provide the best end-to-end performance. For example, the behavior of how many traces TensorFlow will do when the function is repeatedly called with different python scalars as arguments is left undefined to allow for future optimizations.\n",
    "\n",
    "To control the tracing behavior, use the following tools: - different tf.function objects are guaranteed to not share traces; and - specifying a signature or using concrete function objects returned from get_concrete_function() guarantees that only one function graph will be built.\n",
    "\n",
    "Args:\n",
    "func: function to be compiled. If func is None, returns a decorator that can be invoked with a single argument - func. The end result is equivalent to providing all the arguments up front. In other words, tf.function(input_signature=...)(func) is equivalent to tf.function(func, input_signature=...). The former can be used to decorate Python functions, for example: @tf.function(input_signature=...) def foo(...): ...\n",
    "input_signature: A possibly nested sequence of tf.TensorSpec objects specifying the shapes and dtypes of the Tensors that will be supplied to this function. If None, a separate function is instantiated for each inferred input signature. If input_signature is specified, every input to func must be a Tensor, and func cannot accept **kwargs.\n",
    "autograph: Whether autograph should be applied on func before tracing a graph. This allows for dynamic control flow (Python if's, loops etc.) in the traced graph. See https://www.tensorflow.org/guide/autograph for more information.\n",
    "experimental_autograph_options: Experimental knobs (in the form of a tuple of tensorflow.autograph.Feature values) to control behavior when autograph=True.\n",
    "experimental_relax_shapes: When true, argument shapes may be relaxed to avoid unecessary retracing.\n",
    "Returns:\n",
    "If func is not None, returns a callable that will execute the compiled function (and return zero or more tf.Tensor objects). If func is None, returns a decorator that, when invoked with a single func argument, returns a callable equivalent to the case above.\n",
    "\n",
    "Raises:\n",
    "TypeError: If input_signature is neither None nor a sequence of TensorSpec objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Jxv6goXm7oGF"
   ],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "function.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1Hl4PR32Y_nhq4AZI-ku9FlpZIgXjEU7d",
     "timestamp": 1544141357531
    },
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb",
     "timestamp": 1542126584672
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
