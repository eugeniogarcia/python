{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eugenio\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Eugenio\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Eugenio\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Eugenio\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Eugenio\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Eugenio\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_PATH = './'\n",
    "MAX_EPSILON = 1\n",
    "MIN_EPSILON = 0.01\n",
    "LAMBDA = 0.0005\n",
    "GAMMA = 0.95\n",
    "BATCH_SIZE = 32\n",
    "TAU = 0.08\n",
    "RANDOM_REWARD_STD = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "state_size = 4\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_network = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', kernel_initializer=keras.initializers.he_normal()),\n",
    "    keras.layers.Dense(30, activation='relu', kernel_initializer=keras.initializers.he_normal()),\n",
    "    keras.layers.Dense(num_actions)\n",
    "])\n",
    "\n",
    "target_network = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', kernel_initializer=keras.initializers.he_normal()),\n",
    "    keras.layers.Dense(30, activation='relu', kernel_initializer=keras.initializers.he_normal()),\n",
    "    keras.layers.Dense(num_actions)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_network.compile(optimizer=keras.optimizers.Adam(), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, max_memory):\n",
    "        self._max_memory = max_memory\n",
    "        self._samples = []\n",
    "\n",
    "    def add_sample(self, sample):\n",
    "        self._samples.append(sample)\n",
    "        if len(self._samples) > self._max_memory:\n",
    "            self._samples.pop(0)\n",
    "\n",
    "    def sample(self, no_samples):\n",
    "        if no_samples > len(self._samples):\n",
    "            return random.sample(self._samples, len(self._samples))\n",
    "        else:\n",
    "            return random.sample(self._samples, no_samples)\n",
    "\n",
    "    @property\n",
    "    def num_samples(self):\n",
    "        return len(self._samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, primary_network, eps):\n",
    "    if random.random() < eps:\n",
    "        return random.randint(0, num_actions - 1)\n",
    "    else:\n",
    "        return np.argmax(primary_network(state.reshape(1, -1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(primary_network, memory, target_network=None):\n",
    "    #â€“ this is to ensure no training of the primary network takes place \n",
    "    #until there is a reasonable amount of samples within the memory\n",
    "    if memory.num_samples < BATCH_SIZE * 3:\n",
    "        return 0\n",
    "    #a batch is extracted from the memory \n",
    "    batch = memory.sample(BATCH_SIZE)\n",
    "    #individual state, actions and reward values are then extracted and converted\n",
    "    #to numpy arrays using Python list comprehensions\n",
    "    states = np.array([val[0] for val in batch])\n",
    "    actions = np.array([val[1] for val in batch])\n",
    "    rewards = np.array([val[2] for val in batch])\n",
    "    #the next_state values are set to zeros if the raw next_state values are None\n",
    "    next_states = np.array([(np.zeros(state_size) if val[3] is None else val[3]) for val in batch])\n",
    "    \n",
    "    # predict Q(s,a) given the batch of states\n",
    "    prim_qt = primary_network(states)\n",
    "    # predict Q(s',a') from the evaluation network\n",
    "    prim_qtp1 = primary_network(next_states)\n",
    "    \n",
    "    # copy the prim_qt tensor into the target_q tensor - we then will update one index corresponding to the max action\n",
    "    target_q = prim_qt.numpy()\n",
    "    \n",
    "    #Note that the target_q values are the same as the prim_qt () values except for the index \n",
    "    #corresponding to the action chosen\n",
    "    updates = rewards\n",
    "    \n",
    "    #Comprueba para cada una de las muestras que el estado no sea cero. Si lo es significa que no podemos usar la muestra,\n",
    "    # valid_idxs sera un vector con un true en aquellas posiciones donde el next_state estaba informado\n",
    "    valid_idxs = np.array(next_states).sum(axis=1) != 0\n",
    "    \n",
    "    batch_idxs = np.arange(BATCH_SIZE)\n",
    "    \n",
    "    #Esta funciona es valida para DQN y para no DQN\n",
    "    if target_network is None:\n",
    "        #Modo tradicional QN\n",
    "        updates[valid_idxs] += GAMMA * np.amax(prim_qtp1.numpy()[valid_idxs, :], axis=1)\n",
    "    else:\n",
    "        #Modo DQN\n",
    "        prim_action_tp1 = np.argmax(prim_qtp1.numpy(), axis=1)\n",
    "        q_from_target = target_network(next_states)\n",
    "        updates[valid_idxs] += GAMMA * q_from_target.numpy()[batch_idxs[valid_idxs], prim_action_tp1[valid_idxs]]\n",
    "    #calcula el target\n",
    "    target_q[batch_idxs, actions] = updates\n",
    "    \n",
    "    #Entrena el modelo\n",
    "    loss = primary_network.train_on_batch(states, target_q)\n",
    "    \n",
    "    #Copia al modelo target\n",
    "    if target_network is not None:\n",
    "        # Actualiza el modelo target, copiando progresivamente los pesos del modelo principal\n",
    "        for t, e in zip(target_network.trainable_variables, primary_network.trainable_variables):\n",
    "            t.assign(t * (1 - TAU) + e * TAU)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Reward: 22, avg loss: 0.000, eps: 0.989\n",
      "Episode: 1, Reward: 24, avg loss: 0.000, eps: 0.977\n",
      "WARNING:tensorflow:Layer sequential is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Episode: 2, Reward: 14, avg loss: 0.000, eps: 0.969\n",
      "Episode: 3, Reward: 13, avg loss: 0.000, eps: 0.963\n",
      "Episode: 4, Reward: 28, avg loss: 0.542, eps: 0.949\n",
      "Episode: 5, Reward: 9, avg loss: 1.602, eps: 0.944\n",
      "Episode: 6, Reward: 19, avg loss: 1.442, eps: 0.935\n",
      "Episode: 7, Reward: 15, avg loss: 1.731, eps: 0.928\n",
      "Episode: 8, Reward: 17, avg loss: 2.231, eps: 0.919\n",
      "Episode: 9, Reward: 9, avg loss: 1.971, eps: 0.915\n",
      "Episode: 10, Reward: 21, avg loss: 3.381, eps: 0.905\n",
      "Episode: 11, Reward: 10, avg loss: 3.608, eps: 0.900\n",
      "Episode: 12, Reward: 11, avg loss: 4.916, eps: 0.895\n",
      "Episode: 13, Reward: 10, avg loss: 5.502, eps: 0.890\n",
      "Episode: 14, Reward: 26, avg loss: 10.039, eps: 0.878\n",
      "Episode: 15, Reward: 13, avg loss: 8.167, eps: 0.872\n",
      "Episode: 16, Reward: 23, avg loss: 11.534, eps: 0.862\n",
      "Episode: 17, Reward: 10, avg loss: 24.846, eps: 0.857\n",
      "Episode: 18, Reward: 16, avg loss: 15.517, eps: 0.850\n",
      "Episode: 19, Reward: 21, avg loss: 11.333, eps: 0.841\n",
      "Episode: 20, Reward: 19, avg loss: 15.806, eps: 0.832\n",
      "Episode: 21, Reward: 27, avg loss: 17.666, eps: 0.821\n",
      "Episode: 22, Reward: 15, avg loss: 9.428, eps: 0.814\n",
      "Episode: 23, Reward: 11, avg loss: 11.305, eps: 0.810\n",
      "Episode: 24, Reward: 9, avg loss: 12.076, eps: 0.806\n",
      "Episode: 25, Reward: 12, avg loss: 10.427, eps: 0.801\n",
      "Episode: 26, Reward: 8, avg loss: 7.514, eps: 0.797\n",
      "Episode: 27, Reward: 11, avg loss: 7.217, eps: 0.792\n",
      "Episode: 28, Reward: 19, avg loss: 8.922, eps: 0.784\n",
      "Episode: 29, Reward: 12, avg loss: 8.385, eps: 0.779\n",
      "Episode: 30, Reward: 11, avg loss: 9.451, eps: 0.775\n",
      "Episode: 31, Reward: 17, avg loss: 5.618, eps: 0.768\n",
      "Episode: 32, Reward: 13, avg loss: 6.183, eps: 0.763\n",
      "Episode: 33, Reward: 15, avg loss: 7.420, eps: 0.757\n",
      "Episode: 34, Reward: 33, avg loss: 5.609, eps: 0.744\n",
      "Episode: 35, Reward: 29, avg loss: 5.066, eps: 0.733\n",
      "Episode: 36, Reward: 12, avg loss: 7.969, eps: 0.729\n",
      "Episode: 37, Reward: 30, avg loss: 7.524, eps: 0.717\n",
      "Episode: 38, Reward: 12, avg loss: 5.976, eps: 0.713\n",
      "Episode: 39, Reward: 11, avg loss: 9.062, eps: 0.709\n",
      "Episode: 40, Reward: 14, avg loss: 6.501, eps: 0.703\n",
      "Episode: 41, Reward: 12, avg loss: 9.664, eps: 0.699\n",
      "Episode: 42, Reward: 7, avg loss: 5.417, eps: 0.696\n",
      "Episode: 43, Reward: 9, avg loss: 8.455, eps: 0.693\n",
      "Episode: 44, Reward: 14, avg loss: 5.980, eps: 0.688\n",
      "Episode: 45, Reward: 22, avg loss: 6.095, eps: 0.680\n",
      "Episode: 46, Reward: 16, avg loss: 4.758, eps: 0.674\n",
      "Episode: 47, Reward: 52, avg loss: 4.222, eps: 0.657\n",
      "Episode: 48, Reward: 15, avg loss: 2.987, eps: 0.652\n",
      "Episode: 49, Reward: 32, avg loss: 3.122, eps: 0.641\n",
      "Episode: 50, Reward: 69, avg loss: 3.132, eps: 0.620\n",
      "Episode: 51, Reward: 17, avg loss: 2.687, eps: 0.614\n",
      "Episode: 52, Reward: 54, avg loss: 3.470, eps: 0.598\n",
      "Episode: 53, Reward: 129, avg loss: 3.565, eps: 0.561\n",
      "Episode: 54, Reward: 123, avg loss: 3.818, eps: 0.528\n",
      "Episode: 55, Reward: 108, avg loss: 3.338, eps: 0.500\n",
      "Episode: 56, Reward: 87, avg loss: 3.449, eps: 0.479\n",
      "Episode: 57, Reward: 31, avg loss: 3.345, eps: 0.472\n",
      "Episode: 58, Reward: 183, avg loss: 3.646, eps: 0.431\n",
      "Episode: 59, Reward: 165, avg loss: 3.180, eps: 0.397\n",
      "Episode: 60, Reward: 199, avg loss: 3.259, eps: 0.361\n",
      "Episode: 61, Reward: 199, avg loss: 2.730, eps: 0.327\n",
      "Episode: 62, Reward: 199, avg loss: 2.441, eps: 0.297\n",
      "Episode: 63, Reward: 199, avg loss: 2.725, eps: 0.270\n",
      "Episode: 64, Reward: 199, avg loss: 2.160, eps: 0.245\n",
      "Episode: 65, Reward: 199, avg loss: 2.174, eps: 0.223\n",
      "Episode: 66, Reward: 199, avg loss: 2.181, eps: 0.202\n",
      "Episode: 67, Reward: 199, avg loss: 1.990, eps: 0.184\n",
      "Episode: 68, Reward: 199, avg loss: 1.944, eps: 0.168\n",
      "Episode: 69, Reward: 199, avg loss: 2.005, eps: 0.153\n",
      "Episode: 70, Reward: 199, avg loss: 1.899, eps: 0.139\n",
      "Episode: 71, Reward: 199, avg loss: 1.694, eps: 0.127\n",
      "Episode: 72, Reward: 199, avg loss: 2.221, eps: 0.116\n",
      "Episode: 73, Reward: 199, avg loss: 1.965, eps: 0.106\n",
      "Episode: 74, Reward: 199, avg loss: 1.736, eps: 0.096\n",
      "Episode: 75, Reward: 199, avg loss: 1.610, eps: 0.088\n",
      "Episode: 76, Reward: 199, avg loss: 1.576, eps: 0.081\n",
      "Episode: 77, Reward: 199, avg loss: 1.795, eps: 0.074\n",
      "Episode: 78, Reward: 199, avg loss: 1.798, eps: 0.068\n",
      "Episode: 79, Reward: 199, avg loss: 1.668, eps: 0.062\n",
      "Episode: 80, Reward: 199, avg loss: 1.677, eps: 0.057\n",
      "Episode: 81, Reward: 199, avg loss: 1.328, eps: 0.053\n",
      "Episode: 82, Reward: 199, avg loss: 1.841, eps: 0.049\n",
      "Episode: 83, Reward: 199, avg loss: 1.930, eps: 0.045\n",
      "Episode: 84, Reward: 199, avg loss: 1.583, eps: 0.042\n",
      "Episode: 85, Reward: 199, avg loss: 1.601, eps: 0.039\n",
      "Episode: 86, Reward: 199, avg loss: 1.841, eps: 0.036\n",
      "Episode: 87, Reward: 199, avg loss: 1.320, eps: 0.034\n",
      "Episode: 88, Reward: 199, avg loss: 1.733, eps: 0.031\n",
      "Episode: 89, Reward: 199, avg loss: 1.548, eps: 0.029\n",
      "Episode: 90, Reward: 199, avg loss: 1.765, eps: 0.027\n",
      "Episode: 91, Reward: 199, avg loss: 1.629, eps: 0.026\n",
      "Episode: 92, Reward: 199, avg loss: 1.553, eps: 0.024\n",
      "Episode: 93, Reward: 199, avg loss: 1.739, eps: 0.023\n",
      "Episode: 94, Reward: 199, avg loss: 1.486, eps: 0.022\n",
      "Episode: 95, Reward: 199, avg loss: 1.650, eps: 0.021\n",
      "Episode: 96, Reward: 199, avg loss: 1.702, eps: 0.020\n",
      "Episode: 97, Reward: 199, avg loss: 1.517, eps: 0.019\n",
      "Episode: 98, Reward: 199, avg loss: 1.641, eps: 0.018\n",
      "Episode: 99, Reward: 199, avg loss: 1.592, eps: 0.017\n",
      "Episode: 100, Reward: 199, avg loss: 1.647, eps: 0.016\n",
      "Episode: 101, Reward: 199, avg loss: 1.732, eps: 0.016\n",
      "Episode: 102, Reward: 199, avg loss: 1.559, eps: 0.015\n",
      "Episode: 103, Reward: 199, avg loss: 1.562, eps: 0.015\n",
      "Episode: 104, Reward: 199, avg loss: 1.247, eps: 0.014\n",
      "Episode: 105, Reward: 199, avg loss: 1.756, eps: 0.014\n",
      "Episode: 106, Reward: 199, avg loss: 1.195, eps: 0.014\n",
      "Episode: 107, Reward: 199, avg loss: 1.386, eps: 0.013\n",
      "Episode: 108, Reward: 199, avg loss: 1.598, eps: 0.013\n",
      "Episode: 109, Reward: 199, avg loss: 1.497, eps: 0.013\n",
      "Episode: 110, Reward: 199, avg loss: 1.559, eps: 0.012\n",
      "Episode: 111, Reward: 199, avg loss: 1.554, eps: 0.012\n",
      "Episode: 112, Reward: 199, avg loss: 1.655, eps: 0.012\n",
      "Episode: 113, Reward: 199, avg loss: 1.354, eps: 0.012\n",
      "Episode: 114, Reward: 199, avg loss: 1.338, eps: 0.012\n",
      "Episode: 115, Reward: 199, avg loss: 1.349, eps: 0.011\n",
      "Episode: 116, Reward: 199, avg loss: 1.339, eps: 0.011\n",
      "Episode: 117, Reward: 199, avg loss: 1.211, eps: 0.011\n",
      "Episode: 118, Reward: 199, avg loss: 1.340, eps: 0.011\n",
      "Episode: 119, Reward: 199, avg loss: 1.339, eps: 0.011\n",
      "Episode: 120, Reward: 199, avg loss: 1.487, eps: 0.011\n",
      "Episode: 121, Reward: 199, avg loss: 1.233, eps: 0.011\n",
      "Episode: 122, Reward: 199, avg loss: 1.351, eps: 0.011\n",
      "Episode: 123, Reward: 199, avg loss: 1.446, eps: 0.011\n",
      "Episode: 124, Reward: 199, avg loss: 1.340, eps: 0.011\n",
      "Episode: 125, Reward: 199, avg loss: 1.066, eps: 0.011\n",
      "Episode: 126, Reward: 199, avg loss: 1.342, eps: 0.010\n",
      "Episode: 127, Reward: 199, avg loss: 1.622, eps: 0.010\n",
      "Episode: 128, Reward: 199, avg loss: 1.254, eps: 0.010\n",
      "Episode: 129, Reward: 199, avg loss: 1.331, eps: 0.010\n",
      "Episode: 130, Reward: 199, avg loss: 1.439, eps: 0.010\n",
      "Episode: 131, Reward: 199, avg loss: 1.271, eps: 0.010\n",
      "Episode: 132, Reward: 199, avg loss: 1.511, eps: 0.010\n",
      "Episode: 133, Reward: 199, avg loss: 1.025, eps: 0.010\n",
      "Episode: 134, Reward: 199, avg loss: 1.390, eps: 0.010\n",
      "Episode: 135, Reward: 199, avg loss: 1.143, eps: 0.010\n",
      "Episode: 136, Reward: 199, avg loss: 1.423, eps: 0.010\n",
      "Episode: 137, Reward: 199, avg loss: 1.322, eps: 0.010\n",
      "Episode: 138, Reward: 199, avg loss: 1.166, eps: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 139, Reward: 199, avg loss: 1.419, eps: 0.010\n",
      "Episode: 140, Reward: 199, avg loss: 1.276, eps: 0.010\n",
      "Episode: 141, Reward: 199, avg loss: 1.161, eps: 0.010\n",
      "Episode: 142, Reward: 199, avg loss: 1.339, eps: 0.010\n",
      "Episode: 143, Reward: 199, avg loss: 1.116, eps: 0.010\n",
      "Episode: 144, Reward: 199, avg loss: 1.158, eps: 0.010\n",
      "Episode: 145, Reward: 199, avg loss: 1.250, eps: 0.010\n",
      "Episode: 146, Reward: 199, avg loss: 1.075, eps: 0.010\n",
      "Episode: 147, Reward: 199, avg loss: 1.311, eps: 0.010\n",
      "Episode: 148, Reward: 199, avg loss: 1.241, eps: 0.010\n",
      "Episode: 149, Reward: 199, avg loss: 1.129, eps: 0.010\n",
      "Episode: 150, Reward: 199, avg loss: 1.273, eps: 0.010\n",
      "Episode: 151, Reward: 199, avg loss: 1.186, eps: 0.010\n",
      "Episode: 152, Reward: 199, avg loss: 1.279, eps: 0.010\n",
      "Episode: 153, Reward: 199, avg loss: 1.287, eps: 0.010\n",
      "Episode: 154, Reward: 199, avg loss: 1.158, eps: 0.010\n",
      "Episode: 155, Reward: 199, avg loss: 1.351, eps: 0.010\n",
      "Episode: 156, Reward: 199, avg loss: 1.158, eps: 0.010\n",
      "Episode: 157, Reward: 199, avg loss: 1.203, eps: 0.010\n",
      "Episode: 158, Reward: 199, avg loss: 1.331, eps: 0.010\n",
      "Episode: 159, Reward: 199, avg loss: 1.289, eps: 0.010\n",
      "Episode: 160, Reward: 199, avg loss: 1.254, eps: 0.010\n",
      "Episode: 161, Reward: 199, avg loss: 1.210, eps: 0.010\n",
      "Episode: 162, Reward: 199, avg loss: 1.098, eps: 0.010\n",
      "Episode: 163, Reward: 199, avg loss: 1.382, eps: 0.010\n",
      "Episode: 164, Reward: 199, avg loss: 1.142, eps: 0.010\n",
      "Episode: 165, Reward: 199, avg loss: 1.101, eps: 0.010\n",
      "Episode: 166, Reward: 199, avg loss: 1.280, eps: 0.010\n",
      "Episode: 167, Reward: 199, avg loss: 1.193, eps: 0.010\n",
      "Episode: 168, Reward: 199, avg loss: 1.235, eps: 0.010\n",
      "Episode: 169, Reward: 199, avg loss: 1.271, eps: 0.010\n",
      "Episode: 170, Reward: 199, avg loss: 1.254, eps: 0.010\n",
      "Episode: 171, Reward: 199, avg loss: 1.139, eps: 0.010\n",
      "Episode: 172, Reward: 199, avg loss: 1.291, eps: 0.010\n",
      "Episode: 173, Reward: 199, avg loss: 1.363, eps: 0.010\n",
      "Episode: 174, Reward: 199, avg loss: 1.018, eps: 0.010\n",
      "Episode: 175, Reward: 199, avg loss: 0.972, eps: 0.010\n",
      "Episode: 176, Reward: 199, avg loss: 1.431, eps: 0.010\n",
      "Episode: 177, Reward: 199, avg loss: 1.109, eps: 0.010\n",
      "Episode: 178, Reward: 199, avg loss: 1.400, eps: 0.010\n",
      "Episode: 179, Reward: 199, avg loss: 1.166, eps: 0.010\n",
      "Episode: 180, Reward: 199, avg loss: 1.053, eps: 0.010\n",
      "Episode: 181, Reward: 199, avg loss: 1.209, eps: 0.010\n",
      "Episode: 182, Reward: 199, avg loss: 1.168, eps: 0.010\n",
      "Episode: 183, Reward: 199, avg loss: 1.015, eps: 0.010\n",
      "Episode: 184, Reward: 199, avg loss: 1.147, eps: 0.010\n",
      "Episode: 185, Reward: 199, avg loss: 1.177, eps: 0.010\n",
      "Episode: 186, Reward: 199, avg loss: 1.299, eps: 0.010\n",
      "Episode: 187, Reward: 199, avg loss: 1.231, eps: 0.010\n",
      "Episode: 188, Reward: 199, avg loss: 1.287, eps: 0.010\n",
      "Episode: 189, Reward: 199, avg loss: 1.018, eps: 0.010\n",
      "Episode: 190, Reward: 199, avg loss: 1.310, eps: 0.010\n",
      "Episode: 191, Reward: 199, avg loss: 1.052, eps: 0.010\n",
      "Episode: 192, Reward: 199, avg loss: 1.043, eps: 0.010\n",
      "Episode: 193, Reward: 199, avg loss: 1.100, eps: 0.010\n",
      "Episode: 194, Reward: 199, avg loss: 1.139, eps: 0.010\n",
      "Episode: 195, Reward: 199, avg loss: 1.200, eps: 0.010\n",
      "Episode: 196, Reward: 199, avg loss: 1.215, eps: 0.010\n",
      "Episode: 197, Reward: 199, avg loss: 1.222, eps: 0.010\n",
      "Episode: 198, Reward: 199, avg loss: 1.146, eps: 0.010\n",
      "Episode: 199, Reward: 199, avg loss: 1.292, eps: 0.010\n",
      "Episode: 200, Reward: 199, avg loss: 1.037, eps: 0.010\n",
      "Episode: 201, Reward: 199, avg loss: 1.135, eps: 0.010\n",
      "Episode: 202, Reward: 199, avg loss: 1.216, eps: 0.010\n",
      "Episode: 203, Reward: 199, avg loss: 1.048, eps: 0.010\n",
      "Episode: 204, Reward: 199, avg loss: 1.037, eps: 0.010\n",
      "Episode: 205, Reward: 199, avg loss: 1.085, eps: 0.010\n",
      "Episode: 206, Reward: 199, avg loss: 1.085, eps: 0.010\n",
      "Episode: 207, Reward: 199, avg loss: 1.162, eps: 0.010\n",
      "Episode: 208, Reward: 199, avg loss: 1.205, eps: 0.010\n",
      "Episode: 209, Reward: 199, avg loss: 1.201, eps: 0.010\n",
      "Episode: 210, Reward: 199, avg loss: 1.037, eps: 0.010\n",
      "Episode: 211, Reward: 199, avg loss: 1.127, eps: 0.010\n",
      "Episode: 212, Reward: 199, avg loss: 1.175, eps: 0.010\n",
      "Episode: 213, Reward: 199, avg loss: 0.995, eps: 0.010\n",
      "Episode: 214, Reward: 199, avg loss: 1.061, eps: 0.010\n",
      "Episode: 215, Reward: 199, avg loss: 1.102, eps: 0.010\n",
      "Episode: 216, Reward: 199, avg loss: 1.186, eps: 0.010\n",
      "Episode: 217, Reward: 199, avg loss: 0.946, eps: 0.010\n",
      "Episode: 218, Reward: 199, avg loss: 0.908, eps: 0.010\n",
      "Episode: 219, Reward: 199, avg loss: 1.291, eps: 0.010\n",
      "Episode: 220, Reward: 199, avg loss: 1.063, eps: 0.010\n",
      "Episode: 221, Reward: 199, avg loss: 1.101, eps: 0.010\n",
      "Episode: 222, Reward: 199, avg loss: 1.002, eps: 0.010\n",
      "Episode: 223, Reward: 199, avg loss: 1.281, eps: 0.010\n",
      "Episode: 224, Reward: 199, avg loss: 1.021, eps: 0.010\n",
      "Episode: 225, Reward: 199, avg loss: 1.035, eps: 0.010\n",
      "Episode: 226, Reward: 199, avg loss: 1.234, eps: 0.010\n",
      "Episode: 227, Reward: 199, avg loss: 1.301, eps: 0.010\n",
      "Episode: 228, Reward: 199, avg loss: 1.170, eps: 0.010\n",
      "Episode: 229, Reward: 199, avg loss: 1.203, eps: 0.010\n",
      "Episode: 230, Reward: 199, avg loss: 1.241, eps: 0.010\n",
      "Episode: 231, Reward: 199, avg loss: 1.089, eps: 0.010\n",
      "Episode: 232, Reward: 199, avg loss: 0.978, eps: 0.010\n",
      "Episode: 233, Reward: 199, avg loss: 1.109, eps: 0.010\n",
      "Episode: 234, Reward: 199, avg loss: 1.196, eps: 0.010\n",
      "Episode: 235, Reward: 199, avg loss: 1.255, eps: 0.010\n",
      "Episode: 236, Reward: 199, avg loss: 1.034, eps: 0.010\n",
      "Episode: 237, Reward: 199, avg loss: 1.125, eps: 0.010\n",
      "Episode: 238, Reward: 199, avg loss: 1.010, eps: 0.010\n",
      "Episode: 239, Reward: 199, avg loss: 0.946, eps: 0.010\n",
      "Episode: 240, Reward: 199, avg loss: 1.122, eps: 0.010\n",
      "Episode: 241, Reward: 199, avg loss: 1.193, eps: 0.010\n",
      "Episode: 242, Reward: 199, avg loss: 1.162, eps: 0.010\n",
      "Episode: 243, Reward: 199, avg loss: 1.053, eps: 0.010\n",
      "Episode: 244, Reward: 199, avg loss: 1.148, eps: 0.010\n",
      "Episode: 245, Reward: 199, avg loss: 0.999, eps: 0.010\n",
      "Episode: 246, Reward: 199, avg loss: 1.079, eps: 0.010\n",
      "Episode: 247, Reward: 199, avg loss: 1.092, eps: 0.010\n",
      "Episode: 248, Reward: 199, avg loss: 1.105, eps: 0.010\n",
      "Episode: 249, Reward: 199, avg loss: 0.994, eps: 0.010\n",
      "Episode: 250, Reward: 199, avg loss: 1.132, eps: 0.010\n",
      "Episode: 251, Reward: 199, avg loss: 1.196, eps: 0.010\n",
      "Episode: 252, Reward: 199, avg loss: 1.050, eps: 0.010\n",
      "Episode: 253, Reward: 199, avg loss: 0.972, eps: 0.010\n",
      "Episode: 254, Reward: 199, avg loss: 1.176, eps: 0.010\n",
      "Episode: 255, Reward: 199, avg loss: 1.257, eps: 0.010\n",
      "Episode: 256, Reward: 199, avg loss: 1.098, eps: 0.010\n",
      "Episode: 257, Reward: 199, avg loss: 0.869, eps: 0.010\n",
      "Episode: 258, Reward: 199, avg loss: 1.081, eps: 0.010\n",
      "Episode: 259, Reward: 199, avg loss: 1.103, eps: 0.010\n",
      "Episode: 260, Reward: 199, avg loss: 1.005, eps: 0.010\n",
      "Episode: 261, Reward: 199, avg loss: 1.073, eps: 0.010\n",
      "Episode: 262, Reward: 199, avg loss: 1.072, eps: 0.010\n",
      "Episode: 263, Reward: 199, avg loss: 1.249, eps: 0.010\n",
      "Episode: 264, Reward: 199, avg loss: 1.220, eps: 0.010\n",
      "Episode: 265, Reward: 199, avg loss: 1.068, eps: 0.010\n",
      "Episode: 266, Reward: 199, avg loss: 1.130, eps: 0.010\n",
      "Episode: 267, Reward: 199, avg loss: 1.011, eps: 0.010\n",
      "Episode: 268, Reward: 199, avg loss: 1.154, eps: 0.010\n",
      "Episode: 269, Reward: 199, avg loss: 1.083, eps: 0.010\n",
      "Episode: 270, Reward: 199, avg loss: 0.973, eps: 0.010\n",
      "Episode: 271, Reward: 199, avg loss: 1.073, eps: 0.010\n",
      "Episode: 272, Reward: 199, avg loss: 1.110, eps: 0.010\n",
      "Episode: 273, Reward: 199, avg loss: 0.976, eps: 0.010\n",
      "Episode: 274, Reward: 199, avg loss: 0.904, eps: 0.010\n",
      "Episode: 275, Reward: 199, avg loss: 1.155, eps: 0.010\n",
      "Episode: 276, Reward: 199, avg loss: 0.981, eps: 0.010\n",
      "Episode: 277, Reward: 199, avg loss: 0.971, eps: 0.010\n",
      "Episode: 278, Reward: 199, avg loss: 1.148, eps: 0.010\n",
      "Episode: 279, Reward: 199, avg loss: 0.892, eps: 0.010\n",
      "Episode: 280, Reward: 199, avg loss: 1.130, eps: 0.010\n",
      "Episode: 281, Reward: 199, avg loss: 0.869, eps: 0.010\n",
      "Episode: 282, Reward: 199, avg loss: 1.086, eps: 0.010\n",
      "Episode: 283, Reward: 199, avg loss: 0.977, eps: 0.010\n",
      "Episode: 284, Reward: 199, avg loss: 1.041, eps: 0.010\n",
      "Episode: 285, Reward: 199, avg loss: 1.062, eps: 0.010\n",
      "Episode: 286, Reward: 199, avg loss: 0.862, eps: 0.010\n",
      "Episode: 287, Reward: 199, avg loss: 0.994, eps: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 288, Reward: 199, avg loss: 1.051, eps: 0.010\n",
      "Episode: 289, Reward: 199, avg loss: 1.060, eps: 0.010\n",
      "Episode: 290, Reward: 199, avg loss: 0.877, eps: 0.010\n",
      "Episode: 291, Reward: 199, avg loss: 1.026, eps: 0.010\n",
      "Episode: 292, Reward: 199, avg loss: 1.105, eps: 0.010\n",
      "Episode: 293, Reward: 199, avg loss: 1.152, eps: 0.010\n",
      "Episode: 294, Reward: 199, avg loss: 1.154, eps: 0.010\n",
      "Episode: 295, Reward: 199, avg loss: 1.080, eps: 0.010\n",
      "Episode: 296, Reward: 199, avg loss: 0.936, eps: 0.010\n",
      "Episode: 297, Reward: 199, avg loss: 0.992, eps: 0.010\n",
      "Episode: 298, Reward: 199, avg loss: 0.926, eps: 0.010\n",
      "Episode: 299, Reward: 199, avg loss: 1.205, eps: 0.010\n",
      "Episode: 300, Reward: 199, avg loss: 1.195, eps: 0.010\n",
      "Episode: 301, Reward: 199, avg loss: 1.191, eps: 0.010\n",
      "Episode: 302, Reward: 199, avg loss: 0.874, eps: 0.010\n",
      "Episode: 303, Reward: 199, avg loss: 1.116, eps: 0.010\n",
      "Episode: 304, Reward: 199, avg loss: 0.837, eps: 0.010\n",
      "Episode: 305, Reward: 199, avg loss: 1.172, eps: 0.010\n",
      "Episode: 306, Reward: 199, avg loss: 1.163, eps: 0.010\n",
      "Episode: 307, Reward: 199, avg loss: 1.092, eps: 0.010\n",
      "Episode: 308, Reward: 199, avg loss: 0.932, eps: 0.010\n",
      "Episode: 309, Reward: 199, avg loss: 1.077, eps: 0.010\n",
      "Episode: 310, Reward: 199, avg loss: 1.181, eps: 0.010\n",
      "Episode: 311, Reward: 199, avg loss: 1.139, eps: 0.010\n",
      "Episode: 312, Reward: 188, avg loss: 1.071, eps: 0.010\n",
      "Episode: 313, Reward: 199, avg loss: 0.889, eps: 0.010\n",
      "Episode: 314, Reward: 199, avg loss: 1.027, eps: 0.010\n",
      "Episode: 315, Reward: 199, avg loss: 0.997, eps: 0.010\n",
      "Episode: 316, Reward: 199, avg loss: 0.997, eps: 0.010\n",
      "Episode: 317, Reward: 199, avg loss: 0.964, eps: 0.010\n",
      "Episode: 318, Reward: 199, avg loss: 1.131, eps: 0.010\n",
      "Episode: 319, Reward: 199, avg loss: 1.088, eps: 0.010\n",
      "Episode: 320, Reward: 199, avg loss: 1.155, eps: 0.010\n",
      "Episode: 321, Reward: 199, avg loss: 1.250, eps: 0.010\n",
      "Episode: 322, Reward: 186, avg loss: 0.993, eps: 0.010\n",
      "Episode: 323, Reward: 194, avg loss: 1.106, eps: 0.010\n",
      "Episode: 324, Reward: 199, avg loss: 1.000, eps: 0.010\n",
      "Episode: 325, Reward: 199, avg loss: 1.090, eps: 0.010\n",
      "Episode: 326, Reward: 199, avg loss: 0.906, eps: 0.010\n",
      "Episode: 327, Reward: 199, avg loss: 0.982, eps: 0.010\n",
      "Episode: 328, Reward: 199, avg loss: 0.828, eps: 0.010\n",
      "Episode: 329, Reward: 199, avg loss: 1.038, eps: 0.010\n",
      "Episode: 330, Reward: 199, avg loss: 0.804, eps: 0.010\n",
      "Episode: 331, Reward: 199, avg loss: 1.065, eps: 0.010\n",
      "Episode: 332, Reward: 199, avg loss: 0.891, eps: 0.010\n",
      "Episode: 333, Reward: 196, avg loss: 1.056, eps: 0.010\n",
      "Episode: 334, Reward: 199, avg loss: 0.891, eps: 0.010\n",
      "Episode: 335, Reward: 199, avg loss: 1.023, eps: 0.010\n",
      "Episode: 336, Reward: 199, avg loss: 1.113, eps: 0.010\n",
      "Episode: 337, Reward: 78, avg loss: 1.110, eps: 0.010\n",
      "Episode: 338, Reward: 65, avg loss: 0.974, eps: 0.010\n",
      "Episode: 339, Reward: 45, avg loss: 1.386, eps: 0.010\n",
      "Episode: 340, Reward: 43, avg loss: 1.254, eps: 0.010\n",
      "Episode: 341, Reward: 10, avg loss: 2.318, eps: 0.010\n",
      "Episode: 342, Reward: 110, avg loss: 1.302, eps: 0.010\n",
      "Episode: 343, Reward: 199, avg loss: 0.926, eps: 0.010\n",
      "Episode: 344, Reward: 123, avg loss: 1.068, eps: 0.010\n",
      "Episode: 345, Reward: 33, avg loss: 1.242, eps: 0.010\n",
      "Episode: 346, Reward: 199, avg loss: 0.999, eps: 0.010\n",
      "Episode: 347, Reward: 49, avg loss: 1.111, eps: 0.010\n",
      "Episode: 348, Reward: 35, avg loss: 1.096, eps: 0.010\n",
      "Episode: 349, Reward: 33, avg loss: 0.645, eps: 0.010\n",
      "Episode: 350, Reward: 199, avg loss: 0.886, eps: 0.010\n",
      "Episode: 351, Reward: 199, avg loss: 1.139, eps: 0.010\n",
      "Episode: 352, Reward: 199, avg loss: 0.824, eps: 0.010\n",
      "Episode: 353, Reward: 199, avg loss: 0.940, eps: 0.010\n",
      "Episode: 354, Reward: 199, avg loss: 1.017, eps: 0.010\n",
      "Episode: 355, Reward: 199, avg loss: 0.968, eps: 0.010\n",
      "Episode: 356, Reward: 199, avg loss: 1.029, eps: 0.010\n",
      "Episode: 357, Reward: 199, avg loss: 0.886, eps: 0.010\n",
      "Episode: 358, Reward: 199, avg loss: 0.992, eps: 0.010\n",
      "Episode: 359, Reward: 199, avg loss: 1.056, eps: 0.010\n",
      "Episode: 360, Reward: 199, avg loss: 1.054, eps: 0.010\n",
      "Episode: 361, Reward: 197, avg loss: 0.929, eps: 0.010\n",
      "Episode: 362, Reward: 192, avg loss: 0.910, eps: 0.010\n",
      "Episode: 363, Reward: 199, avg loss: 0.846, eps: 0.010\n",
      "Episode: 364, Reward: 199, avg loss: 1.056, eps: 0.010\n",
      "Episode: 365, Reward: 199, avg loss: 1.040, eps: 0.010\n",
      "Episode: 366, Reward: 199, avg loss: 1.075, eps: 0.010\n",
      "Episode: 367, Reward: 199, avg loss: 0.947, eps: 0.010\n",
      "Episode: 368, Reward: 199, avg loss: 1.028, eps: 0.010\n",
      "Episode: 369, Reward: 199, avg loss: 1.011, eps: 0.010\n",
      "Episode: 370, Reward: 199, avg loss: 1.078, eps: 0.010\n",
      "Episode: 371, Reward: 199, avg loss: 0.871, eps: 0.010\n",
      "Episode: 372, Reward: 199, avg loss: 1.097, eps: 0.010\n",
      "Episode: 373, Reward: 199, avg loss: 1.068, eps: 0.010\n",
      "Episode: 374, Reward: 199, avg loss: 0.974, eps: 0.010\n",
      "Episode: 375, Reward: 199, avg loss: 1.216, eps: 0.010\n",
      "Episode: 376, Reward: 199, avg loss: 1.091, eps: 0.010\n",
      "Episode: 377, Reward: 199, avg loss: 0.959, eps: 0.010\n",
      "Episode: 378, Reward: 199, avg loss: 0.949, eps: 0.010\n",
      "Episode: 379, Reward: 199, avg loss: 1.056, eps: 0.010\n",
      "Episode: 380, Reward: 199, avg loss: 0.982, eps: 0.010\n",
      "Episode: 381, Reward: 199, avg loss: 0.916, eps: 0.010\n",
      "Episode: 382, Reward: 199, avg loss: 0.909, eps: 0.010\n",
      "Episode: 383, Reward: 199, avg loss: 0.984, eps: 0.010\n",
      "Episode: 384, Reward: 194, avg loss: 0.997, eps: 0.010\n",
      "Episode: 385, Reward: 199, avg loss: 0.935, eps: 0.010\n",
      "Episode: 386, Reward: 197, avg loss: 1.029, eps: 0.010\n",
      "Episode: 387, Reward: 199, avg loss: 1.016, eps: 0.010\n",
      "Episode: 388, Reward: 199, avg loss: 0.922, eps: 0.010\n",
      "Episode: 389, Reward: 199, avg loss: 0.952, eps: 0.010\n",
      "Episode: 390, Reward: 199, avg loss: 1.061, eps: 0.010\n",
      "Episode: 391, Reward: 199, avg loss: 1.109, eps: 0.010\n",
      "Episode: 392, Reward: 199, avg loss: 1.088, eps: 0.010\n",
      "Episode: 393, Reward: 199, avg loss: 0.992, eps: 0.010\n",
      "Episode: 394, Reward: 199, avg loss: 0.960, eps: 0.010\n",
      "Episode: 395, Reward: 151, avg loss: 1.075, eps: 0.010\n",
      "Episode: 396, Reward: 199, avg loss: 0.998, eps: 0.010\n",
      "Episode: 397, Reward: 199, avg loss: 0.989, eps: 0.010\n",
      "Episode: 398, Reward: 199, avg loss: 0.934, eps: 0.010\n",
      "Episode: 399, Reward: 199, avg loss: 0.894, eps: 0.010\n",
      "Episode: 400, Reward: 199, avg loss: 0.789, eps: 0.010\n",
      "Episode: 401, Reward: 186, avg loss: 1.099, eps: 0.010\n",
      "Episode: 402, Reward: 199, avg loss: 1.105, eps: 0.010\n",
      "Episode: 403, Reward: 172, avg loss: 1.075, eps: 0.010\n",
      "Episode: 404, Reward: 176, avg loss: 1.055, eps: 0.010\n",
      "Episode: 405, Reward: 199, avg loss: 1.026, eps: 0.010\n",
      "Episode: 406, Reward: 152, avg loss: 1.110, eps: 0.010\n",
      "Episode: 407, Reward: 199, avg loss: 1.012, eps: 0.010\n",
      "Episode: 408, Reward: 199, avg loss: 1.020, eps: 0.010\n",
      "Episode: 409, Reward: 182, avg loss: 1.114, eps: 0.010\n",
      "Episode: 410, Reward: 199, avg loss: 1.009, eps: 0.010\n",
      "Episode: 411, Reward: 199, avg loss: 1.035, eps: 0.010\n",
      "Episode: 412, Reward: 199, avg loss: 0.927, eps: 0.010\n",
      "Episode: 413, Reward: 199, avg loss: 1.129, eps: 0.010\n",
      "Episode: 414, Reward: 178, avg loss: 1.259, eps: 0.010\n",
      "Episode: 415, Reward: 199, avg loss: 1.093, eps: 0.010\n",
      "Episode: 416, Reward: 191, avg loss: 0.963, eps: 0.010\n",
      "Episode: 417, Reward: 134, avg loss: 1.308, eps: 0.010\n",
      "Episode: 418, Reward: 165, avg loss: 1.236, eps: 0.010\n",
      "Episode: 419, Reward: 199, avg loss: 1.074, eps: 0.010\n",
      "Episode: 420, Reward: 199, avg loss: 0.960, eps: 0.010\n",
      "Episode: 421, Reward: 199, avg loss: 1.157, eps: 0.010\n",
      "Episode: 422, Reward: 199, avg loss: 0.970, eps: 0.010\n",
      "Episode: 423, Reward: 199, avg loss: 1.035, eps: 0.010\n",
      "Episode: 424, Reward: 199, avg loss: 1.105, eps: 0.010\n",
      "Episode: 425, Reward: 199, avg loss: 1.051, eps: 0.010\n",
      "Episode: 426, Reward: 171, avg loss: 1.033, eps: 0.010\n",
      "Episode: 427, Reward: 163, avg loss: 1.140, eps: 0.010\n",
      "Episode: 428, Reward: 199, avg loss: 1.078, eps: 0.010\n",
      "Episode: 429, Reward: 199, avg loss: 1.162, eps: 0.010\n",
      "Episode: 430, Reward: 199, avg loss: 1.078, eps: 0.010\n",
      "Episode: 431, Reward: 199, avg loss: 0.960, eps: 0.010\n",
      "Episode: 432, Reward: 199, avg loss: 1.071, eps: 0.010\n",
      "Episode: 433, Reward: 199, avg loss: 0.961, eps: 0.010\n",
      "Episode: 434, Reward: 199, avg loss: 1.044, eps: 0.010\n",
      "Episode: 435, Reward: 194, avg loss: 1.046, eps: 0.010\n",
      "Episode: 436, Reward: 199, avg loss: 1.085, eps: 0.010\n",
      "Episode: 437, Reward: 199, avg loss: 0.996, eps: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 438, Reward: 199, avg loss: 0.885, eps: 0.010\n",
      "Episode: 439, Reward: 199, avg loss: 0.932, eps: 0.010\n",
      "Episode: 440, Reward: 199, avg loss: 1.108, eps: 0.010\n",
      "Episode: 441, Reward: 191, avg loss: 1.102, eps: 0.010\n",
      "Episode: 442, Reward: 199, avg loss: 0.984, eps: 0.010\n",
      "Episode: 443, Reward: 199, avg loss: 1.039, eps: 0.010\n",
      "Episode: 444, Reward: 199, avg loss: 0.981, eps: 0.010\n",
      "Episode: 445, Reward: 166, avg loss: 0.945, eps: 0.010\n",
      "Episode: 446, Reward: 184, avg loss: 1.110, eps: 0.010\n",
      "Episode: 447, Reward: 155, avg loss: 1.129, eps: 0.010\n",
      "Episode: 448, Reward: 143, avg loss: 1.073, eps: 0.010\n",
      "Episode: 449, Reward: 194, avg loss: 1.141, eps: 0.010\n",
      "Episode: 450, Reward: 199, avg loss: 0.939, eps: 0.010\n",
      "Episode: 451, Reward: 199, avg loss: 1.000, eps: 0.010\n",
      "Episode: 452, Reward: 168, avg loss: 0.987, eps: 0.010\n",
      "Episode: 453, Reward: 199, avg loss: 1.087, eps: 0.010\n",
      "Episode: 454, Reward: 174, avg loss: 0.881, eps: 0.010\n",
      "Episode: 455, Reward: 199, avg loss: 1.023, eps: 0.010\n",
      "Episode: 456, Reward: 165, avg loss: 1.316, eps: 0.010\n",
      "Episode: 457, Reward: 199, avg loss: 0.987, eps: 0.010\n",
      "Episode: 458, Reward: 199, avg loss: 1.036, eps: 0.010\n",
      "Episode: 459, Reward: 187, avg loss: 1.062, eps: 0.010\n",
      "Episode: 460, Reward: 199, avg loss: 1.116, eps: 0.010\n",
      "Episode: 461, Reward: 199, avg loss: 1.024, eps: 0.010\n",
      "Episode: 462, Reward: 189, avg loss: 1.102, eps: 0.010\n",
      "Episode: 463, Reward: 199, avg loss: 1.038, eps: 0.010\n",
      "Episode: 464, Reward: 199, avg loss: 1.173, eps: 0.010\n",
      "Episode: 465, Reward: 173, avg loss: 1.019, eps: 0.010\n",
      "Episode: 466, Reward: 199, avg loss: 1.000, eps: 0.010\n",
      "Episode: 467, Reward: 119, avg loss: 1.029, eps: 0.010\n",
      "Episode: 468, Reward: 199, avg loss: 0.941, eps: 0.010\n",
      "Episode: 469, Reward: 199, avg loss: 1.218, eps: 0.010\n",
      "Episode: 470, Reward: 131, avg loss: 0.911, eps: 0.010\n",
      "Episode: 471, Reward: 194, avg loss: 0.863, eps: 0.010\n",
      "Episode: 472, Reward: 144, avg loss: 0.865, eps: 0.010\n",
      "Episode: 473, Reward: 199, avg loss: 1.022, eps: 0.010\n",
      "Episode: 474, Reward: 199, avg loss: 0.942, eps: 0.010\n",
      "Episode: 475, Reward: 161, avg loss: 0.960, eps: 0.010\n",
      "Episode: 476, Reward: 177, avg loss: 0.919, eps: 0.010\n",
      "Episode: 477, Reward: 127, avg loss: 1.020, eps: 0.010\n",
      "Episode: 478, Reward: 199, avg loss: 1.019, eps: 0.010\n",
      "Episode: 479, Reward: 181, avg loss: 1.150, eps: 0.010\n",
      "Episode: 480, Reward: 199, avg loss: 0.910, eps: 0.010\n",
      "Episode: 481, Reward: 171, avg loss: 0.932, eps: 0.010\n",
      "Episode: 482, Reward: 199, avg loss: 1.025, eps: 0.010\n",
      "Episode: 483, Reward: 184, avg loss: 1.055, eps: 0.010\n",
      "Episode: 484, Reward: 126, avg loss: 1.052, eps: 0.010\n",
      "Episode: 485, Reward: 172, avg loss: 0.967, eps: 0.010\n",
      "Episode: 486, Reward: 199, avg loss: 1.026, eps: 0.010\n",
      "Episode: 487, Reward: 199, avg loss: 0.988, eps: 0.010\n",
      "Episode: 488, Reward: 184, avg loss: 1.160, eps: 0.010\n",
      "Episode: 489, Reward: 199, avg loss: 0.916, eps: 0.010\n",
      "Episode: 490, Reward: 116, avg loss: 0.833, eps: 0.010\n",
      "Episode: 491, Reward: 160, avg loss: 1.164, eps: 0.010\n",
      "Episode: 492, Reward: 181, avg loss: 1.107, eps: 0.010\n",
      "Episode: 493, Reward: 199, avg loss: 1.041, eps: 0.010\n",
      "Episode: 494, Reward: 199, avg loss: 0.953, eps: 0.010\n",
      "Episode: 495, Reward: 160, avg loss: 1.274, eps: 0.010\n",
      "Episode: 496, Reward: 199, avg loss: 0.908, eps: 0.010\n",
      "Episode: 497, Reward: 166, avg loss: 1.047, eps: 0.010\n",
      "Episode: 498, Reward: 144, avg loss: 1.098, eps: 0.010\n",
      "Episode: 499, Reward: 139, avg loss: 1.080, eps: 0.010\n",
      "Episode: 500, Reward: 171, avg loss: 1.025, eps: 0.010\n",
      "Episode: 501, Reward: 175, avg loss: 0.975, eps: 0.010\n",
      "Episode: 502, Reward: 180, avg loss: 1.045, eps: 0.010\n",
      "Episode: 503, Reward: 199, avg loss: 0.941, eps: 0.010\n",
      "Episode: 504, Reward: 167, avg loss: 0.938, eps: 0.010\n",
      "Episode: 505, Reward: 132, avg loss: 0.967, eps: 0.010\n",
      "Episode: 506, Reward: 199, avg loss: 0.967, eps: 0.010\n",
      "Episode: 507, Reward: 194, avg loss: 0.902, eps: 0.010\n",
      "Episode: 508, Reward: 199, avg loss: 0.913, eps: 0.010\n",
      "Episode: 509, Reward: 137, avg loss: 1.041, eps: 0.010\n",
      "Episode: 510, Reward: 199, avg loss: 1.158, eps: 0.010\n",
      "Episode: 511, Reward: 196, avg loss: 0.924, eps: 0.010\n",
      "Episode: 512, Reward: 199, avg loss: 0.966, eps: 0.010\n",
      "Episode: 513, Reward: 175, avg loss: 0.905, eps: 0.010\n",
      "Episode: 514, Reward: 178, avg loss: 1.158, eps: 0.010\n",
      "Episode: 515, Reward: 185, avg loss: 0.977, eps: 0.010\n",
      "Episode: 516, Reward: 146, avg loss: 1.041, eps: 0.010\n",
      "Episode: 517, Reward: 27, avg loss: 0.815, eps: 0.010\n",
      "Episode: 518, Reward: 27, avg loss: 0.874, eps: 0.010\n",
      "Episode: 519, Reward: 105, avg loss: 1.260, eps: 0.010\n",
      "Episode: 520, Reward: 189, avg loss: 1.137, eps: 0.010\n",
      "Episode: 521, Reward: 122, avg loss: 0.972, eps: 0.010\n",
      "Episode: 522, Reward: 192, avg loss: 0.682, eps: 0.010\n",
      "Episode: 523, Reward: 183, avg loss: 1.003, eps: 0.010\n",
      "Episode: 524, Reward: 199, avg loss: 1.142, eps: 0.010\n",
      "Episode: 525, Reward: 151, avg loss: 0.979, eps: 0.010\n",
      "Episode: 526, Reward: 138, avg loss: 1.031, eps: 0.010\n",
      "Episode: 527, Reward: 170, avg loss: 0.980, eps: 0.010\n",
      "Episode: 528, Reward: 193, avg loss: 1.025, eps: 0.010\n",
      "Episode: 529, Reward: 199, avg loss: 0.947, eps: 0.010\n",
      "Episode: 530, Reward: 156, avg loss: 1.112, eps: 0.010\n",
      "Episode: 531, Reward: 171, avg loss: 1.055, eps: 0.010\n",
      "Episode: 532, Reward: 170, avg loss: 0.995, eps: 0.010\n",
      "Episode: 533, Reward: 155, avg loss: 1.110, eps: 0.010\n",
      "Episode: 534, Reward: 199, avg loss: 1.221, eps: 0.010\n",
      "Episode: 535, Reward: 199, avg loss: 1.061, eps: 0.010\n",
      "Episode: 536, Reward: 153, avg loss: 1.065, eps: 0.010\n",
      "Episode: 537, Reward: 199, avg loss: 0.963, eps: 0.010\n",
      "Episode: 538, Reward: 176, avg loss: 1.018, eps: 0.010\n",
      "Episode: 539, Reward: 185, avg loss: 0.968, eps: 0.010\n",
      "Episode: 540, Reward: 199, avg loss: 0.993, eps: 0.010\n",
      "Episode: 541, Reward: 122, avg loss: 0.933, eps: 0.010\n",
      "Episode: 542, Reward: 152, avg loss: 1.065, eps: 0.010\n",
      "Episode: 543, Reward: 199, avg loss: 0.829, eps: 0.010\n",
      "Episode: 544, Reward: 199, avg loss: 0.840, eps: 0.010\n",
      "Episode: 545, Reward: 174, avg loss: 0.915, eps: 0.010\n",
      "Episode: 546, Reward: 177, avg loss: 1.119, eps: 0.010\n",
      "Episode: 547, Reward: 155, avg loss: 1.210, eps: 0.010\n",
      "Episode: 548, Reward: 108, avg loss: 1.078, eps: 0.010\n",
      "Episode: 549, Reward: 126, avg loss: 1.072, eps: 0.010\n",
      "Episode: 550, Reward: 156, avg loss: 1.166, eps: 0.010\n",
      "Episode: 551, Reward: 162, avg loss: 0.916, eps: 0.010\n",
      "Episode: 552, Reward: 177, avg loss: 0.964, eps: 0.010\n",
      "Episode: 553, Reward: 159, avg loss: 1.027, eps: 0.010\n",
      "Episode: 554, Reward: 152, avg loss: 0.895, eps: 0.010\n",
      "Episode: 555, Reward: 160, avg loss: 0.906, eps: 0.010\n",
      "Episode: 556, Reward: 150, avg loss: 1.088, eps: 0.010\n",
      "Episode: 557, Reward: 140, avg loss: 0.863, eps: 0.010\n",
      "Episode: 558, Reward: 163, avg loss: 0.994, eps: 0.010\n",
      "Episode: 559, Reward: 178, avg loss: 1.028, eps: 0.010\n",
      "Episode: 560, Reward: 166, avg loss: 0.973, eps: 0.010\n",
      "Episode: 561, Reward: 144, avg loss: 0.837, eps: 0.010\n",
      "Episode: 562, Reward: 199, avg loss: 0.771, eps: 0.010\n",
      "Episode: 563, Reward: 199, avg loss: 0.923, eps: 0.010\n",
      "Episode: 564, Reward: 199, avg loss: 0.955, eps: 0.010\n",
      "Episode: 565, Reward: 199, avg loss: 0.947, eps: 0.010\n",
      "Episode: 566, Reward: 199, avg loss: 1.040, eps: 0.010\n",
      "Episode: 567, Reward: 145, avg loss: 0.824, eps: 0.010\n",
      "Episode: 568, Reward: 166, avg loss: 0.880, eps: 0.010\n",
      "Episode: 569, Reward: 199, avg loss: 0.941, eps: 0.010\n",
      "Episode: 570, Reward: 135, avg loss: 1.118, eps: 0.010\n",
      "Episode: 571, Reward: 175, avg loss: 0.903, eps: 0.010\n",
      "Episode: 572, Reward: 199, avg loss: 0.991, eps: 0.010\n",
      "Episode: 573, Reward: 123, avg loss: 0.826, eps: 0.010\n",
      "Episode: 574, Reward: 199, avg loss: 1.043, eps: 0.010\n",
      "Episode: 575, Reward: 199, avg loss: 0.788, eps: 0.010\n",
      "Episode: 576, Reward: 199, avg loss: 0.868, eps: 0.010\n",
      "Episode: 577, Reward: 194, avg loss: 0.848, eps: 0.010\n",
      "Episode: 578, Reward: 149, avg loss: 0.844, eps: 0.010\n",
      "Episode: 579, Reward: 115, avg loss: 0.833, eps: 0.010\n",
      "Episode: 580, Reward: 199, avg loss: 0.822, eps: 0.010\n",
      "Episode: 581, Reward: 199, avg loss: 0.787, eps: 0.010\n",
      "Episode: 582, Reward: 199, avg loss: 0.951, eps: 0.010\n",
      "Episode: 583, Reward: 139, avg loss: 0.758, eps: 0.010\n",
      "Episode: 584, Reward: 176, avg loss: 0.979, eps: 0.010\n",
      "Episode: 585, Reward: 199, avg loss: 0.949, eps: 0.010\n",
      "Episode: 586, Reward: 199, avg loss: 0.887, eps: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 587, Reward: 184, avg loss: 0.865, eps: 0.010\n",
      "Episode: 588, Reward: 179, avg loss: 0.822, eps: 0.010\n",
      "Episode: 589, Reward: 143, avg loss: 0.911, eps: 0.010\n",
      "Episode: 590, Reward: 118, avg loss: 0.858, eps: 0.010\n",
      "Episode: 591, Reward: 199, avg loss: 0.941, eps: 0.010\n",
      "Episode: 592, Reward: 199, avg loss: 0.988, eps: 0.010\n",
      "Episode: 593, Reward: 140, avg loss: 0.934, eps: 0.010\n",
      "Episode: 594, Reward: 144, avg loss: 0.939, eps: 0.010\n",
      "Episode: 595, Reward: 157, avg loss: 0.982, eps: 0.010\n",
      "Episode: 596, Reward: 124, avg loss: 0.772, eps: 0.010\n",
      "Episode: 597, Reward: 160, avg loss: 0.820, eps: 0.010\n",
      "Episode: 598, Reward: 128, avg loss: 0.964, eps: 0.010\n",
      "Episode: 599, Reward: 133, avg loss: 0.881, eps: 0.010\n",
      "Episode: 600, Reward: 127, avg loss: 0.938, eps: 0.010\n",
      "Episode: 601, Reward: 140, avg loss: 0.964, eps: 0.010\n",
      "Episode: 602, Reward: 164, avg loss: 0.867, eps: 0.010\n",
      "Episode: 603, Reward: 177, avg loss: 0.944, eps: 0.010\n",
      "Episode: 604, Reward: 145, avg loss: 0.760, eps: 0.010\n",
      "Episode: 605, Reward: 138, avg loss: 0.839, eps: 0.010\n",
      "Episode: 606, Reward: 199, avg loss: 0.889, eps: 0.010\n",
      "Episode: 607, Reward: 30, avg loss: 1.102, eps: 0.010\n",
      "Episode: 608, Reward: 124, avg loss: 0.917, eps: 0.010\n",
      "Episode: 609, Reward: 126, avg loss: 0.974, eps: 0.010\n",
      "Episode: 610, Reward: 151, avg loss: 0.794, eps: 0.010\n",
      "Episode: 611, Reward: 199, avg loss: 1.120, eps: 0.010\n",
      "Episode: 612, Reward: 195, avg loss: 0.845, eps: 0.010\n",
      "Episode: 613, Reward: 117, avg loss: 0.913, eps: 0.010\n",
      "Episode: 614, Reward: 113, avg loss: 0.912, eps: 0.010\n",
      "Episode: 615, Reward: 199, avg loss: 0.864, eps: 0.010\n",
      "Episode: 616, Reward: 199, avg loss: 0.926, eps: 0.010\n",
      "Episode: 617, Reward: 172, avg loss: 0.848, eps: 0.010\n",
      "Episode: 618, Reward: 199, avg loss: 1.011, eps: 0.010\n",
      "Episode: 619, Reward: 141, avg loss: 0.998, eps: 0.010\n",
      "Episode: 620, Reward: 199, avg loss: 1.065, eps: 0.010\n",
      "Episode: 621, Reward: 199, avg loss: 0.910, eps: 0.010\n",
      "Episode: 622, Reward: 199, avg loss: 0.887, eps: 0.010\n",
      "Episode: 623, Reward: 199, avg loss: 0.895, eps: 0.010\n",
      "Episode: 624, Reward: 122, avg loss: 0.998, eps: 0.010\n",
      "Episode: 625, Reward: 124, avg loss: 0.952, eps: 0.010\n",
      "Episode: 626, Reward: 185, avg loss: 0.847, eps: 0.010\n",
      "Episode: 627, Reward: 151, avg loss: 0.818, eps: 0.010\n",
      "Episode: 628, Reward: 158, avg loss: 0.818, eps: 0.010\n",
      "Episode: 629, Reward: 125, avg loss: 0.788, eps: 0.010\n",
      "Episode: 630, Reward: 150, avg loss: 0.951, eps: 0.010\n",
      "Episode: 631, Reward: 15, avg loss: 0.645, eps: 0.010\n",
      "Episode: 632, Reward: 199, avg loss: 0.760, eps: 0.010\n",
      "Episode: 633, Reward: 164, avg loss: 0.783, eps: 0.010\n",
      "Episode: 634, Reward: 126, avg loss: 0.846, eps: 0.010\n",
      "Episode: 635, Reward: 180, avg loss: 0.830, eps: 0.010\n",
      "Episode: 636, Reward: 122, avg loss: 0.883, eps: 0.010\n",
      "Episode: 637, Reward: 125, avg loss: 0.787, eps: 0.010\n",
      "Episode: 638, Reward: 132, avg loss: 0.966, eps: 0.010\n",
      "Episode: 639, Reward: 110, avg loss: 0.799, eps: 0.010\n",
      "Episode: 640, Reward: 29, avg loss: 1.130, eps: 0.010\n",
      "Episode: 641, Reward: 107, avg loss: 0.944, eps: 0.010\n",
      "Episode: 642, Reward: 116, avg loss: 1.011, eps: 0.010\n",
      "Episode: 643, Reward: 168, avg loss: 0.760, eps: 0.010\n",
      "Episode: 644, Reward: 199, avg loss: 0.761, eps: 0.010\n",
      "Episode: 645, Reward: 199, avg loss: 0.844, eps: 0.010\n",
      "Episode: 646, Reward: 43, avg loss: 1.206, eps: 0.010\n",
      "Episode: 647, Reward: 126, avg loss: 0.776, eps: 0.010\n",
      "Episode: 648, Reward: 115, avg loss: 0.737, eps: 0.010\n",
      "Episode: 649, Reward: 199, avg loss: 0.844, eps: 0.010\n",
      "Episode: 650, Reward: 171, avg loss: 0.962, eps: 0.010\n",
      "Episode: 651, Reward: 134, avg loss: 0.811, eps: 0.010\n",
      "Episode: 652, Reward: 199, avg loss: 0.969, eps: 0.010\n",
      "Episode: 653, Reward: 199, avg loss: 0.848, eps: 0.010\n",
      "Episode: 654, Reward: 129, avg loss: 0.744, eps: 0.010\n",
      "Episode: 655, Reward: 199, avg loss: 0.944, eps: 0.010\n",
      "Episode: 656, Reward: 170, avg loss: 0.969, eps: 0.010\n",
      "Episode: 657, Reward: 199, avg loss: 0.909, eps: 0.010\n",
      "Episode: 658, Reward: 175, avg loss: 0.857, eps: 0.010\n",
      "Episode: 659, Reward: 130, avg loss: 1.089, eps: 0.010\n",
      "Episode: 660, Reward: 111, avg loss: 0.972, eps: 0.010\n",
      "Episode: 661, Reward: 13, avg loss: 1.073, eps: 0.010\n",
      "Episode: 662, Reward: 134, avg loss: 0.770, eps: 0.010\n",
      "Episode: 663, Reward: 109, avg loss: 1.007, eps: 0.010\n",
      "Episode: 664, Reward: 160, avg loss: 0.852, eps: 0.010\n",
      "Episode: 665, Reward: 199, avg loss: 0.813, eps: 0.010\n",
      "Episode: 666, Reward: 176, avg loss: 0.867, eps: 0.010\n",
      "Episode: 667, Reward: 199, avg loss: 0.831, eps: 0.010\n",
      "Episode: 668, Reward: 142, avg loss: 0.835, eps: 0.010\n",
      "Episode: 669, Reward: 182, avg loss: 0.855, eps: 0.010\n",
      "Episode: 670, Reward: 118, avg loss: 0.739, eps: 0.010\n",
      "Episode: 671, Reward: 199, avg loss: 0.846, eps: 0.010\n",
      "Episode: 672, Reward: 126, avg loss: 0.889, eps: 0.010\n",
      "Episode: 673, Reward: 199, avg loss: 0.905, eps: 0.010\n",
      "Episode: 674, Reward: 137, avg loss: 1.132, eps: 0.010\n",
      "Episode: 675, Reward: 146, avg loss: 0.798, eps: 0.010\n",
      "Episode: 676, Reward: 199, avg loss: 0.722, eps: 0.010\n",
      "Episode: 677, Reward: 199, avg loss: 1.034, eps: 0.010\n",
      "Episode: 678, Reward: 143, avg loss: 0.781, eps: 0.010\n",
      "Episode: 679, Reward: 199, avg loss: 0.846, eps: 0.010\n",
      "Episode: 680, Reward: 199, avg loss: 1.002, eps: 0.010\n",
      "Episode: 681, Reward: 199, avg loss: 0.828, eps: 0.010\n",
      "Episode: 682, Reward: 144, avg loss: 0.757, eps: 0.010\n",
      "Episode: 683, Reward: 161, avg loss: 0.750, eps: 0.010\n",
      "Episode: 684, Reward: 150, avg loss: 0.948, eps: 0.010\n",
      "Episode: 685, Reward: 167, avg loss: 0.782, eps: 0.010\n",
      "Episode: 686, Reward: 176, avg loss: 0.830, eps: 0.010\n",
      "Episode: 687, Reward: 133, avg loss: 0.824, eps: 0.010\n",
      "Episode: 688, Reward: 145, avg loss: 0.730, eps: 0.010\n",
      "Episode: 689, Reward: 185, avg loss: 0.857, eps: 0.010\n",
      "Episode: 690, Reward: 117, avg loss: 0.799, eps: 0.010\n",
      "Episode: 691, Reward: 178, avg loss: 0.910, eps: 0.010\n",
      "Episode: 692, Reward: 199, avg loss: 0.953, eps: 0.010\n",
      "Episode: 693, Reward: 106, avg loss: 0.996, eps: 0.010\n",
      "Episode: 694, Reward: 125, avg loss: 0.933, eps: 0.010\n",
      "Episode: 695, Reward: 14, avg loss: 0.979, eps: 0.010\n",
      "Episode: 696, Reward: 125, avg loss: 0.788, eps: 0.010\n",
      "Episode: 697, Reward: 157, avg loss: 0.923, eps: 0.010\n",
      "Episode: 698, Reward: 162, avg loss: 0.815, eps: 0.010\n",
      "Episode: 699, Reward: 199, avg loss: 0.991, eps: 0.010\n",
      "Episode: 700, Reward: 130, avg loss: 0.919, eps: 0.010\n",
      "Episode: 701, Reward: 199, avg loss: 0.827, eps: 0.010\n",
      "Episode: 702, Reward: 117, avg loss: 0.954, eps: 0.010\n",
      "Episode: 703, Reward: 158, avg loss: 0.887, eps: 0.010\n",
      "Episode: 704, Reward: 157, avg loss: 0.960, eps: 0.010\n",
      "Episode: 705, Reward: 154, avg loss: 0.914, eps: 0.010\n",
      "Episode: 706, Reward: 189, avg loss: 0.859, eps: 0.010\n",
      "Episode: 707, Reward: 126, avg loss: 0.807, eps: 0.010\n",
      "Episode: 708, Reward: 151, avg loss: 0.857, eps: 0.010\n",
      "Episode: 709, Reward: 132, avg loss: 0.933, eps: 0.010\n",
      "Episode: 710, Reward: 154, avg loss: 0.894, eps: 0.010\n",
      "Episode: 711, Reward: 199, avg loss: 0.826, eps: 0.010\n",
      "Episode: 712, Reward: 129, avg loss: 0.922, eps: 0.010\n",
      "Episode: 713, Reward: 135, avg loss: 0.858, eps: 0.010\n",
      "Episode: 714, Reward: 134, avg loss: 1.023, eps: 0.010\n",
      "Episode: 715, Reward: 176, avg loss: 0.965, eps: 0.010\n",
      "Episode: 716, Reward: 158, avg loss: 0.844, eps: 0.010\n",
      "Episode: 717, Reward: 144, avg loss: 0.881, eps: 0.010\n",
      "Episode: 718, Reward: 147, avg loss: 0.863, eps: 0.010\n",
      "Episode: 719, Reward: 197, avg loss: 0.779, eps: 0.010\n",
      "Episode: 720, Reward: 119, avg loss: 0.752, eps: 0.010\n",
      "Episode: 721, Reward: 199, avg loss: 0.885, eps: 0.010\n",
      "Episode: 722, Reward: 166, avg loss: 0.867, eps: 0.010\n",
      "Episode: 723, Reward: 156, avg loss: 0.849, eps: 0.010\n",
      "Episode: 724, Reward: 199, avg loss: 0.896, eps: 0.010\n",
      "Episode: 725, Reward: 183, avg loss: 0.789, eps: 0.010\n",
      "Episode: 726, Reward: 160, avg loss: 0.946, eps: 0.010\n",
      "Episode: 727, Reward: 199, avg loss: 0.838, eps: 0.010\n",
      "Episode: 728, Reward: 137, avg loss: 0.733, eps: 0.010\n",
      "Episode: 729, Reward: 157, avg loss: 0.856, eps: 0.010\n",
      "Episode: 730, Reward: 143, avg loss: 1.091, eps: 0.010\n",
      "Episode: 731, Reward: 169, avg loss: 0.695, eps: 0.010\n",
      "Episode: 732, Reward: 199, avg loss: 0.802, eps: 0.010\n",
      "Episode: 733, Reward: 129, avg loss: 0.720, eps: 0.010\n",
      "Episode: 734, Reward: 130, avg loss: 0.693, eps: 0.010\n",
      "Episode: 735, Reward: 122, avg loss: 0.677, eps: 0.010\n",
      "Episode: 736, Reward: 157, avg loss: 0.754, eps: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 737, Reward: 133, avg loss: 0.733, eps: 0.010\n",
      "Episode: 738, Reward: 129, avg loss: 0.913, eps: 0.010\n",
      "Episode: 739, Reward: 165, avg loss: 0.675, eps: 0.010\n",
      "Episode: 740, Reward: 114, avg loss: 0.741, eps: 0.010\n",
      "Episode: 741, Reward: 199, avg loss: 0.845, eps: 0.010\n",
      "Episode: 742, Reward: 164, avg loss: 0.703, eps: 0.010\n",
      "Episode: 743, Reward: 154, avg loss: 0.824, eps: 0.010\n",
      "Episode: 744, Reward: 149, avg loss: 0.686, eps: 0.010\n",
      "Episode: 745, Reward: 176, avg loss: 0.851, eps: 0.010\n",
      "Episode: 746, Reward: 184, avg loss: 0.841, eps: 0.010\n",
      "Episode: 747, Reward: 144, avg loss: 0.842, eps: 0.010\n",
      "Episode: 748, Reward: 183, avg loss: 0.750, eps: 0.010\n",
      "Episode: 749, Reward: 158, avg loss: 0.851, eps: 0.010\n",
      "Episode: 750, Reward: 124, avg loss: 0.816, eps: 0.010\n",
      "Episode: 751, Reward: 150, avg loss: 0.851, eps: 0.010\n",
      "Episode: 752, Reward: 151, avg loss: 0.739, eps: 0.010\n",
      "Episode: 753, Reward: 138, avg loss: 0.854, eps: 0.010\n",
      "Episode: 754, Reward: 124, avg loss: 0.870, eps: 0.010\n",
      "Episode: 755, Reward: 199, avg loss: 0.722, eps: 0.010\n",
      "Episode: 756, Reward: 161, avg loss: 0.962, eps: 0.010\n",
      "Episode: 757, Reward: 194, avg loss: 0.788, eps: 0.010\n",
      "Episode: 758, Reward: 199, avg loss: 0.669, eps: 0.010\n",
      "Episode: 759, Reward: 112, avg loss: 0.823, eps: 0.010\n",
      "Episode: 760, Reward: 199, avg loss: 0.820, eps: 0.010\n",
      "Episode: 761, Reward: 199, avg loss: 0.986, eps: 0.010\n",
      "Episode: 762, Reward: 126, avg loss: 0.624, eps: 0.010\n",
      "Episode: 763, Reward: 199, avg loss: 0.903, eps: 0.010\n",
      "Episode: 764, Reward: 132, avg loss: 0.840, eps: 0.010\n",
      "Episode: 765, Reward: 139, avg loss: 0.956, eps: 0.010\n",
      "Episode: 766, Reward: 199, avg loss: 0.815, eps: 0.010\n",
      "Episode: 767, Reward: 134, avg loss: 0.675, eps: 0.010\n",
      "Episode: 768, Reward: 126, avg loss: 0.736, eps: 0.010\n",
      "Episode: 769, Reward: 122, avg loss: 0.982, eps: 0.010\n",
      "Episode: 770, Reward: 188, avg loss: 0.757, eps: 0.010\n",
      "Episode: 771, Reward: 199, avg loss: 0.784, eps: 0.010\n",
      "Episode: 772, Reward: 141, avg loss: 0.781, eps: 0.010\n",
      "Episode: 773, Reward: 110, avg loss: 0.861, eps: 0.010\n",
      "Episode: 774, Reward: 160, avg loss: 0.856, eps: 0.010\n",
      "Episode: 775, Reward: 139, avg loss: 0.798, eps: 0.010\n",
      "Episode: 776, Reward: 170, avg loss: 0.783, eps: 0.010\n",
      "Episode: 777, Reward: 131, avg loss: 0.858, eps: 0.010\n",
      "Episode: 778, Reward: 27, avg loss: 1.033, eps: 0.010\n",
      "Episode: 779, Reward: 199, avg loss: 0.717, eps: 0.010\n",
      "Episode: 780, Reward: 167, avg loss: 0.860, eps: 0.010\n",
      "Episode: 781, Reward: 188, avg loss: 0.852, eps: 0.010\n",
      "Episode: 782, Reward: 195, avg loss: 0.832, eps: 0.010\n",
      "Episode: 783, Reward: 149, avg loss: 0.856, eps: 0.010\n",
      "Episode: 784, Reward: 153, avg loss: 1.097, eps: 0.010\n",
      "Episode: 785, Reward: 139, avg loss: 0.861, eps: 0.010\n",
      "Episode: 786, Reward: 149, avg loss: 0.828, eps: 0.010\n",
      "Episode: 787, Reward: 163, avg loss: 0.824, eps: 0.010\n",
      "Episode: 788, Reward: 136, avg loss: 0.646, eps: 0.010\n",
      "Episode: 789, Reward: 131, avg loss: 0.737, eps: 0.010\n",
      "Episode: 790, Reward: 148, avg loss: 0.891, eps: 0.010\n",
      "Episode: 791, Reward: 158, avg loss: 0.871, eps: 0.010\n",
      "Episode: 792, Reward: 160, avg loss: 0.960, eps: 0.010\n",
      "Episode: 793, Reward: 165, avg loss: 0.839, eps: 0.010\n",
      "Episode: 794, Reward: 144, avg loss: 0.732, eps: 0.010\n",
      "Episode: 795, Reward: 163, avg loss: 0.776, eps: 0.010\n",
      "Episode: 796, Reward: 135, avg loss: 0.797, eps: 0.010\n",
      "Episode: 797, Reward: 150, avg loss: 0.685, eps: 0.010\n",
      "Episode: 798, Reward: 199, avg loss: 0.737, eps: 0.010\n",
      "Episode: 799, Reward: 169, avg loss: 0.796, eps: 0.010\n",
      "Episode: 800, Reward: 163, avg loss: 0.705, eps: 0.010\n",
      "Episode: 801, Reward: 126, avg loss: 0.766, eps: 0.010\n",
      "Episode: 802, Reward: 174, avg loss: 0.801, eps: 0.010\n",
      "Episode: 803, Reward: 169, avg loss: 0.808, eps: 0.010\n",
      "Episode: 804, Reward: 139, avg loss: 0.797, eps: 0.010\n",
      "Episode: 805, Reward: 160, avg loss: 0.757, eps: 0.010\n",
      "Episode: 806, Reward: 173, avg loss: 0.882, eps: 0.010\n",
      "Episode: 807, Reward: 199, avg loss: 0.716, eps: 0.010\n",
      "Episode: 808, Reward: 125, avg loss: 0.885, eps: 0.010\n",
      "Episode: 809, Reward: 151, avg loss: 0.648, eps: 0.010\n",
      "Episode: 810, Reward: 147, avg loss: 0.734, eps: 0.010\n",
      "Episode: 811, Reward: 146, avg loss: 0.734, eps: 0.010\n",
      "Episode: 812, Reward: 147, avg loss: 0.712, eps: 0.010\n",
      "Episode: 813, Reward: 199, avg loss: 0.846, eps: 0.010\n",
      "Episode: 814, Reward: 199, avg loss: 0.736, eps: 0.010\n",
      "Episode: 815, Reward: 43, avg loss: 0.886, eps: 0.010\n",
      "Episode: 816, Reward: 199, avg loss: 0.868, eps: 0.010\n",
      "Episode: 817, Reward: 199, avg loss: 0.730, eps: 0.010\n",
      "Episode: 818, Reward: 137, avg loss: 0.761, eps: 0.010\n",
      "Episode: 819, Reward: 135, avg loss: 0.637, eps: 0.010\n",
      "Episode: 820, Reward: 125, avg loss: 0.758, eps: 0.010\n",
      "Episode: 821, Reward: 59, avg loss: 0.835, eps: 0.010\n",
      "Episode: 822, Reward: 118, avg loss: 0.791, eps: 0.010\n",
      "Episode: 823, Reward: 126, avg loss: 0.783, eps: 0.010\n",
      "Episode: 824, Reward: 199, avg loss: 0.745, eps: 0.010\n",
      "Episode: 825, Reward: 199, avg loss: 0.667, eps: 0.010\n",
      "Episode: 826, Reward: 167, avg loss: 0.838, eps: 0.010\n",
      "Episode: 827, Reward: 168, avg loss: 0.750, eps: 0.010\n",
      "Episode: 828, Reward: 127, avg loss: 0.788, eps: 0.010\n",
      "Episode: 829, Reward: 141, avg loss: 0.801, eps: 0.010\n",
      "Episode: 830, Reward: 135, avg loss: 0.811, eps: 0.010\n",
      "Episode: 831, Reward: 115, avg loss: 0.874, eps: 0.010\n",
      "Episode: 832, Reward: 108, avg loss: 0.731, eps: 0.010\n",
      "Episode: 833, Reward: 127, avg loss: 0.814, eps: 0.010\n",
      "Episode: 834, Reward: 148, avg loss: 0.665, eps: 0.010\n",
      "Episode: 835, Reward: 167, avg loss: 0.764, eps: 0.010\n",
      "Episode: 836, Reward: 122, avg loss: 0.926, eps: 0.010\n",
      "Episode: 837, Reward: 64, avg loss: 0.723, eps: 0.010\n",
      "Episode: 838, Reward: 199, avg loss: 0.869, eps: 0.010\n",
      "Episode: 839, Reward: 188, avg loss: 0.806, eps: 0.010\n",
      "Episode: 840, Reward: 196, avg loss: 0.691, eps: 0.010\n",
      "Episode: 841, Reward: 163, avg loss: 0.801, eps: 0.010\n",
      "Episode: 842, Reward: 123, avg loss: 0.702, eps: 0.010\n",
      "Episode: 843, Reward: 143, avg loss: 0.939, eps: 0.010\n",
      "Episode: 844, Reward: 13, avg loss: 0.629, eps: 0.010\n",
      "Episode: 845, Reward: 129, avg loss: 0.952, eps: 0.010\n",
      "Episode: 846, Reward: 136, avg loss: 0.807, eps: 0.010\n",
      "Episode: 847, Reward: 137, avg loss: 0.783, eps: 0.010\n",
      "Episode: 848, Reward: 183, avg loss: 0.807, eps: 0.010\n",
      "Episode: 849, Reward: 131, avg loss: 0.781, eps: 0.010\n",
      "Episode: 850, Reward: 131, avg loss: 0.744, eps: 0.010\n",
      "Episode: 851, Reward: 154, avg loss: 0.787, eps: 0.010\n",
      "Episode: 852, Reward: 123, avg loss: 0.792, eps: 0.010\n",
      "Episode: 853, Reward: 199, avg loss: 0.774, eps: 0.010\n",
      "Episode: 854, Reward: 199, avg loss: 0.811, eps: 0.010\n",
      "Episode: 855, Reward: 199, avg loss: 0.815, eps: 0.010\n",
      "Episode: 856, Reward: 143, avg loss: 0.759, eps: 0.010\n",
      "Episode: 857, Reward: 145, avg loss: 0.655, eps: 0.010\n",
      "Episode: 858, Reward: 199, avg loss: 0.768, eps: 0.010\n",
      "Episode: 859, Reward: 158, avg loss: 0.695, eps: 0.010\n",
      "Episode: 860, Reward: 157, avg loss: 0.865, eps: 0.010\n",
      "Episode: 861, Reward: 123, avg loss: 0.661, eps: 0.010\n",
      "Episode: 862, Reward: 199, avg loss: 0.918, eps: 0.010\n",
      "Episode: 863, Reward: 120, avg loss: 0.746, eps: 0.010\n",
      "Episode: 864, Reward: 138, avg loss: 0.834, eps: 0.010\n",
      "Episode: 865, Reward: 118, avg loss: 0.753, eps: 0.010\n",
      "Episode: 866, Reward: 128, avg loss: 0.817, eps: 0.010\n",
      "Episode: 867, Reward: 135, avg loss: 0.666, eps: 0.010\n",
      "Episode: 868, Reward: 152, avg loss: 0.741, eps: 0.010\n",
      "Episode: 869, Reward: 199, avg loss: 0.636, eps: 0.010\n",
      "Episode: 870, Reward: 181, avg loss: 0.695, eps: 0.010\n",
      "Episode: 871, Reward: 199, avg loss: 0.723, eps: 0.010\n",
      "Episode: 872, Reward: 159, avg loss: 0.740, eps: 0.010\n",
      "Episode: 873, Reward: 132, avg loss: 0.824, eps: 0.010\n",
      "Episode: 874, Reward: 198, avg loss: 0.746, eps: 0.010\n",
      "Episode: 875, Reward: 133, avg loss: 0.836, eps: 0.010\n",
      "Episode: 876, Reward: 158, avg loss: 0.858, eps: 0.010\n",
      "Episode: 877, Reward: 120, avg loss: 0.821, eps: 0.010\n",
      "Episode: 878, Reward: 199, avg loss: 0.827, eps: 0.010\n",
      "Episode: 879, Reward: 199, avg loss: 0.892, eps: 0.010\n",
      "Episode: 880, Reward: 123, avg loss: 0.891, eps: 0.010\n",
      "Episode: 881, Reward: 199, avg loss: 0.768, eps: 0.010\n",
      "Episode: 882, Reward: 141, avg loss: 0.723, eps: 0.010\n",
      "Episode: 883, Reward: 153, avg loss: 0.760, eps: 0.010\n",
      "Episode: 884, Reward: 126, avg loss: 0.647, eps: 0.010\n",
      "Episode: 885, Reward: 143, avg loss: 0.884, eps: 0.010\n",
      "Episode: 886, Reward: 163, avg loss: 0.897, eps: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 887, Reward: 199, avg loss: 0.786, eps: 0.010\n",
      "Episode: 888, Reward: 163, avg loss: 0.837, eps: 0.010\n",
      "Episode: 889, Reward: 199, avg loss: 0.888, eps: 0.010\n",
      "Episode: 890, Reward: 129, avg loss: 0.744, eps: 0.010\n",
      "Episode: 891, Reward: 138, avg loss: 0.735, eps: 0.010\n",
      "Episode: 892, Reward: 166, avg loss: 0.766, eps: 0.010\n",
      "Episode: 893, Reward: 195, avg loss: 0.837, eps: 0.010\n",
      "Episode: 894, Reward: 146, avg loss: 0.685, eps: 0.010\n",
      "Episode: 895, Reward: 199, avg loss: 0.778, eps: 0.010\n",
      "Episode: 896, Reward: 178, avg loss: 0.743, eps: 0.010\n",
      "Episode: 897, Reward: 136, avg loss: 0.814, eps: 0.010\n",
      "Episode: 898, Reward: 150, avg loss: 0.821, eps: 0.010\n",
      "Episode: 899, Reward: 199, avg loss: 0.799, eps: 0.010\n",
      "Episode: 900, Reward: 199, avg loss: 0.793, eps: 0.010\n",
      "Episode: 901, Reward: 127, avg loss: 0.743, eps: 0.010\n",
      "Episode: 902, Reward: 199, avg loss: 0.698, eps: 0.010\n",
      "Episode: 903, Reward: 126, avg loss: 0.725, eps: 0.010\n",
      "Episode: 904, Reward: 121, avg loss: 0.662, eps: 0.010\n",
      "Episode: 905, Reward: 199, avg loss: 0.702, eps: 0.010\n",
      "Episode: 906, Reward: 199, avg loss: 0.696, eps: 0.010\n",
      "Episode: 907, Reward: 142, avg loss: 0.791, eps: 0.010\n",
      "Episode: 908, Reward: 117, avg loss: 0.721, eps: 0.010\n",
      "Episode: 909, Reward: 129, avg loss: 0.732, eps: 0.010\n",
      "Episode: 910, Reward: 166, avg loss: 0.688, eps: 0.010\n",
      "Episode: 911, Reward: 66, avg loss: 0.814, eps: 0.010\n",
      "Episode: 912, Reward: 134, avg loss: 0.759, eps: 0.010\n",
      "Episode: 913, Reward: 116, avg loss: 0.933, eps: 0.010\n",
      "Episode: 914, Reward: 163, avg loss: 0.779, eps: 0.010\n",
      "Episode: 915, Reward: 192, avg loss: 0.894, eps: 0.010\n",
      "Episode: 916, Reward: 199, avg loss: 0.731, eps: 0.010\n",
      "Episode: 917, Reward: 171, avg loss: 0.789, eps: 0.010\n",
      "Episode: 918, Reward: 148, avg loss: 0.675, eps: 0.010\n",
      "Episode: 919, Reward: 199, avg loss: 0.827, eps: 0.010\n",
      "Episode: 920, Reward: 166, avg loss: 0.672, eps: 0.010\n",
      "Episode: 921, Reward: 78, avg loss: 0.778, eps: 0.010\n",
      "Episode: 922, Reward: 21, avg loss: 0.579, eps: 0.010\n",
      "Episode: 923, Reward: 118, avg loss: 0.925, eps: 0.010\n",
      "Episode: 924, Reward: 160, avg loss: 0.813, eps: 0.010\n",
      "Episode: 925, Reward: 192, avg loss: 0.877, eps: 0.010\n",
      "Episode: 926, Reward: 126, avg loss: 0.785, eps: 0.010\n",
      "Episode: 927, Reward: 123, avg loss: 0.791, eps: 0.010\n",
      "Episode: 928, Reward: 152, avg loss: 0.862, eps: 0.010\n",
      "Episode: 929, Reward: 163, avg loss: 0.797, eps: 0.010\n",
      "Episode: 930, Reward: 199, avg loss: 0.720, eps: 0.010\n",
      "Episode: 931, Reward: 129, avg loss: 0.742, eps: 0.010\n",
      "Episode: 932, Reward: 144, avg loss: 0.762, eps: 0.010\n",
      "Episode: 933, Reward: 175, avg loss: 0.827, eps: 0.010\n",
      "Episode: 934, Reward: 199, avg loss: 0.799, eps: 0.010\n",
      "Episode: 935, Reward: 199, avg loss: 0.842, eps: 0.010\n",
      "Episode: 936, Reward: 137, avg loss: 0.680, eps: 0.010\n",
      "Episode: 937, Reward: 137, avg loss: 0.761, eps: 0.010\n",
      "Episode: 938, Reward: 199, avg loss: 0.705, eps: 0.010\n",
      "Episode: 939, Reward: 199, avg loss: 0.821, eps: 0.010\n",
      "Episode: 940, Reward: 128, avg loss: 0.737, eps: 0.010\n",
      "Episode: 941, Reward: 160, avg loss: 0.683, eps: 0.010\n",
      "Episode: 942, Reward: 199, avg loss: 0.715, eps: 0.010\n",
      "Episode: 943, Reward: 182, avg loss: 0.626, eps: 0.010\n",
      "Episode: 944, Reward: 181, avg loss: 0.695, eps: 0.010\n",
      "Episode: 945, Reward: 161, avg loss: 0.894, eps: 0.010\n",
      "Episode: 946, Reward: 153, avg loss: 0.876, eps: 0.010\n",
      "Episode: 947, Reward: 199, avg loss: 0.760, eps: 0.010\n",
      "Episode: 948, Reward: 175, avg loss: 0.858, eps: 0.010\n",
      "Episode: 949, Reward: 180, avg loss: 0.809, eps: 0.010\n",
      "Episode: 950, Reward: 199, avg loss: 0.726, eps: 0.010\n",
      "Episode: 951, Reward: 122, avg loss: 0.824, eps: 0.010\n",
      "Episode: 952, Reward: 151, avg loss: 0.823, eps: 0.010\n",
      "Episode: 953, Reward: 195, avg loss: 0.676, eps: 0.010\n",
      "Episode: 954, Reward: 123, avg loss: 0.744, eps: 0.010\n",
      "Episode: 955, Reward: 150, avg loss: 0.951, eps: 0.010\n",
      "Episode: 956, Reward: 148, avg loss: 0.703, eps: 0.010\n",
      "Episode: 957, Reward: 164, avg loss: 0.808, eps: 0.010\n",
      "Episode: 958, Reward: 136, avg loss: 0.730, eps: 0.010\n",
      "Episode: 959, Reward: 152, avg loss: 0.722, eps: 0.010\n",
      "Episode: 960, Reward: 130, avg loss: 0.690, eps: 0.010\n",
      "Episode: 961, Reward: 195, avg loss: 0.777, eps: 0.010\n",
      "Episode: 962, Reward: 159, avg loss: 0.674, eps: 0.010\n",
      "Episode: 963, Reward: 161, avg loss: 0.779, eps: 0.010\n",
      "Episode: 964, Reward: 138, avg loss: 0.763, eps: 0.010\n",
      "Episode: 965, Reward: 161, avg loss: 0.753, eps: 0.010\n",
      "Episode: 966, Reward: 180, avg loss: 0.654, eps: 0.010\n",
      "Episode: 967, Reward: 167, avg loss: 0.763, eps: 0.010\n",
      "Episode: 968, Reward: 138, avg loss: 0.624, eps: 0.010\n",
      "Episode: 969, Reward: 147, avg loss: 0.810, eps: 0.010\n",
      "Episode: 970, Reward: 152, avg loss: 0.786, eps: 0.010\n",
      "Episode: 971, Reward: 133, avg loss: 0.742, eps: 0.010\n",
      "Episode: 972, Reward: 132, avg loss: 0.725, eps: 0.010\n",
      "Episode: 973, Reward: 173, avg loss: 0.718, eps: 0.010\n",
      "Episode: 974, Reward: 199, avg loss: 0.833, eps: 0.010\n",
      "Episode: 975, Reward: 137, avg loss: 0.723, eps: 0.010\n",
      "Episode: 976, Reward: 139, avg loss: 0.836, eps: 0.010\n",
      "Episode: 977, Reward: 120, avg loss: 0.787, eps: 0.010\n",
      "Episode: 978, Reward: 142, avg loss: 0.773, eps: 0.010\n",
      "Episode: 979, Reward: 123, avg loss: 0.712, eps: 0.010\n",
      "Episode: 980, Reward: 119, avg loss: 0.852, eps: 0.010\n",
      "Episode: 981, Reward: 164, avg loss: 0.689, eps: 0.010\n",
      "Episode: 982, Reward: 163, avg loss: 0.691, eps: 0.010\n",
      "Episode: 983, Reward: 118, avg loss: 0.892, eps: 0.010\n",
      "Episode: 984, Reward: 157, avg loss: 0.835, eps: 0.010\n",
      "Episode: 985, Reward: 155, avg loss: 0.626, eps: 0.010\n",
      "Episode: 986, Reward: 175, avg loss: 0.675, eps: 0.010\n",
      "Episode: 987, Reward: 199, avg loss: 0.808, eps: 0.010\n",
      "Episode: 988, Reward: 175, avg loss: 0.612, eps: 0.010\n",
      "Episode: 989, Reward: 182, avg loss: 0.673, eps: 0.010\n",
      "Episode: 990, Reward: 184, avg loss: 0.601, eps: 0.010\n",
      "Episode: 991, Reward: 199, avg loss: 0.626, eps: 0.010\n",
      "Episode: 992, Reward: 167, avg loss: 0.981, eps: 0.010\n",
      "Episode: 993, Reward: 129, avg loss: 0.707, eps: 0.010\n",
      "Episode: 994, Reward: 155, avg loss: 0.697, eps: 0.010\n",
      "Episode: 995, Reward: 152, avg loss: 0.780, eps: 0.010\n",
      "Episode: 996, Reward: 138, avg loss: 0.779, eps: 0.010\n",
      "Episode: 997, Reward: 199, avg loss: 0.685, eps: 0.010\n",
      "Episode: 998, Reward: 165, avg loss: 0.742, eps: 0.010\n",
      "Episode: 999, Reward: 111, avg loss: 0.793, eps: 0.010\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "eps = MAX_EPSILON\n",
    "#No visualizamos\n",
    "render = False\n",
    "train_writer = tf.summary.create_file_writer(STORE_PATH + f\"/DoubleQ_{dt.datetime.now().strftime('%d%m%Y%H%M')}\")\n",
    "#If double_q is set to False, the training function defaults to standard deep Q learning\n",
    "double_q = False\n",
    "                                             \n",
    "steps = 0\n",
    "for i in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    cnt = 0\n",
    "    avg_loss = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        #Elije la accion usando la primary network                                     \n",
    "        action = choose_action(state, primary_network, eps)\n",
    "        #Ejecuta la accion\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        #Hacemos el entorno estocastico\n",
    "        reward = np.random.normal(1.0, RANDOM_REWARD_STD)\n",
    "        \n",
    "        if done:\n",
    "            next_state = None\n",
    "        \n",
    "        # guardamos en la memoria, el estado, la accion, la recompensa y el siguiente estado\n",
    "        memory.add_sample((state, action, reward, next_state))\n",
    "\n",
    "        #Entrenamos\n",
    "        loss = train(primary_network, memory, target_network if double_q else None)\n",
    "        avg_loss += loss\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        # exponentially decay the eps value\n",
    "        steps += 1\n",
    "        eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * math.exp(-LAMBDA * steps)\n",
    "\n",
    "        #Terminamos\n",
    "        if done:\n",
    "            avg_loss /= cnt\n",
    "            print(f\"Episode: {i}, Reward: {cnt}, avg loss: {avg_loss:.3f}, eps: {eps:.3f}\")\n",
    "            with train_writer.as_default():\n",
    "                tf.summary.scalar('reward', cnt, step=i)\n",
    "                tf.summary.scalar('avg loss', avg_loss, step=i)\n",
    "            break\n",
    "\n",
    "        cnt += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
